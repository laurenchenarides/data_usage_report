[
  {
    "objectID": "webinar_questionnaire.html",
    "href": "webinar_questionnaire.html",
    "title": "Questionnaire",
    "section": "",
    "text": "Complete Questionnaire \n\nLoading…\n\n\n\n\n\nInterested in staying involved? If you’d like to join a working group to continue the conversation and help shape next steps, please provide your contact information. Participation is completely optional.\n\n Sign Up Here \n\nLoading…",
    "crumbs": [
      "Questionnaire"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "How to Cite:\n\n\n\nChenarides, L., Bryan, C., & Ladislau, R. (2025). Methodology for comparing citation database coverage of dataset usage. Available at: https://laurenchenarides.github.io/data_usage_report/report.html",
    "crumbs": [
      "Report Summary"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe gratefully acknowledge the contributions of the following individuals:\n\nJulia Lane, Ph.D. (New York University) – for guidance on methodology and feedback on drafts.\nMing Wang, Ph.D. (Colorado State University) – for research assistance.",
    "crumbs": [
      "Report Summary"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA dataset mention refers to an instance in which a specific dataset is referenced, cited, or named within a research publication. This can occur in various parts of the text, such as the abstract, methods, data section, footnotes, or references, and typically indicates that the dataset was used, analyzed, or discussed in the study.↩︎\nFull-text search in OpenAlex refers to querying the entire database for textual mentions of dataset names within titles, abstracts, and other fields.↩︎\nThe seed corpus search involves selecting a targeted set of publications based on journal, author, and topic filters. Full-text PDFs are downloaded and analyzed to identify mentions of USDA datasets not captured through metadata alone.↩︎",
    "crumbs": [
      "Report Summary"
    ]
  },
  {
    "objectID": "code/flatten_openalex_all_datasets.html",
    "href": "code/flatten_openalex_all_datasets.html",
    "title": "Looped over all datasets",
    "section": "",
    "text": "Use the NASS case to create a loop across all json’s in the folder:\nOutput: - A dataset_reference_table.csv file with all your filenames and IDs - A folder for each dataset: - flattened_dataset01/ - dataset01_main.csv - dataset01_authorships.csv … - flattened_dataset02/ - dataset02_main.csv …\nEverything is neatly contained and reproducible.\n# Step 1: List and tag all JSON files\nimport os\nimport pandas as pd\n\n# Set the folder where the JSON files live\ndata_dir = \".\"  # or specify full path if needed\n\n# List all .json files\njson_files = [f for f in os.listdir(data_dir) if f.endswith(\".json\")]\njson_files.sort()  # ensure consistent ordering\n\n# Create IDs like dataset01, dataset02...\ndataset_ids = [f\"dataset{str(i+1).zfill(2)}\" for i in range(len(json_files))]\n\n# Create reference table\nreference_table = pd.DataFrame({\n    \"dataset_id\": dataset_ids,\n    \"filename\": json_files\n})\n\n# Save reference table\nreference_table.to_csv(\"dataset_reference_table.csv\", index=False)\nprint(reference_table)\n\n   dataset_id                                           filename\n0   dataset01                                          ARMS.json\n1   dataset02  Current Population Survey Food Security Supple...\n2   dataset03                         Farm to School Census.json\n3   dataset04    Information Resources, Inc. (IRI) InfoScan.json\n4   dataset05                    NASS Census of Agriculture.json\n5   dataset06                                          RUCC.json\n6   dataset07  Tenure, ownership, and transition of agricultu...\n7   dataset08                    food access research atlas.json\n8   dataset09          food acquisition and purchase survey.json\n9   dataset10         household food security survey module.json\n10  dataset11         local food marketing practices survey.json\n11  dataset12         quarterly food at home price database.json\n12  dataset13        transition of agricultural land survey.json\n# Step 2: Loop through each JSON and apply flattening\n\n# Define fields to exclude from flattening\nexclude_fields = [\n    \"keywords\",\n    \"sustainable_development_goals\",\n    \"mesh\",\n    \"referenced_works\",\n    \"related_works\",\n    \"abstract_inverted_index\",\n    \"plain_text\",\n    \"concepts\",\n    \"locations\"\n]\n\n# Check if a value is a nested structure\ndef is_nested(val):\n    return isinstance(val, (list, dict))\n\ndef deep_flatten_field(data, field, id_key=\"id\"):\n    rows = []\n    for rec in data:\n        parent_id = rec.get(id_key)\n        items = rec.get(field, [])\n\n        if isinstance(items, dict):\n            flat = flatten(items)\n            flat['parent_id'] = parent_id\n            rows.append(flat)\n        elif isinstance(items, list):\n            for item in items:\n                if isinstance(item, dict):\n                    flat = flatten(item)\n                    flat['parent_id'] = parent_id\n                    rows.append(flat)\n                else:\n                    rows.append({'value': item, 'parent_id': parent_id})\n\n    return pd.DataFrame(rows) if rows else pd.DataFrame()\n# Step 3: Process all datasets\n\nimport json\nfrom flatten_json import flatten\n\nimport csv\n\nfor i, row in reference_table.iterrows():\n    dataset_id = row[\"dataset_id\"]\n    file_name = row[\"filename\"]\n    print(f\"\\n Processing {file_name} → {dataset_id}\")\n\n    # Load JSON\n    with open(os.path.join(data_dir, file_name), \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    # Flatten top level\n    df_main = pd.DataFrame([flatten(record) for record in data])\n\n    # Save main flat table\n    output_dir = f\"flattened_{dataset_id}\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    # ---- Clean any old CSV files ----\n    for f in os.listdir(output_dir):\n        if f.endswith(\".csv\"):\n            os.remove(os.path.join(output_dir, f))\n    \n    main_csv_path = os.path.join(output_dir, f\"{dataset_id}_main.csv\")\n    df_main.to_csv(main_csv_path, index=False, quoting=csv.QUOTE_ALL, escapechar='\\\\')\n\n    # Validate saved main CSV\n    try:\n        # Suppress DtypeWarning by adding low_memory=False\n        _ = pd.read_csv(main_csv_path, low_memory=False)\n        print(f\"Validated: {main_csv_path}\")\n    except Exception as e:\n        print(f\"Validation error in {main_csv_path}: {e}\")\n\n    # Identify nested fields\n    nested_fields = set()\n    for rec in data:\n        for k, v in rec.items():\n            if k not in exclude_fields and is_nested(v):\n                nested_fields.add(k)\n\n    # Flatten each nested field\n    for field in nested_fields:\n        df_nested = deep_flatten_field(data, field)\n        if not df_nested.empty:\n            nested_csv_path = os.path.join(output_dir, f\"{dataset_id}_{field}.csv\")\n            df_nested.to_csv(nested_csv_path, index=False, quoting=csv.QUOTE_ALL, escapechar='\\\\')\n\n            # Validate nested saved CSV\n            try:\n                # Suppress DtypeWarning here too\n                _ = pd.read_csv(nested_csv_path, low_memory=False)\n                print(f\"Validated: {nested_csv_path}\")\n            except Exception as e:\n                print(f\"Validation error in {nested_csv_path}: {e}\")\n\n    print(f\"Finished processing {dataset_id} — saved to {output_dir}\")\n\n\n Processing ARMS.json → dataset01\nValidated: flattened_dataset01\\dataset01_main.csv\nValidated: flattened_dataset01\\dataset01_corresponding_author_ids.csv\nValidated: flattened_dataset01\\dataset01_grants.csv\nValidated: flattened_dataset01\\dataset01_apc_list.csv\nValidated: flattened_dataset01\\dataset01_indexed_in.csv\nValidated: flattened_dataset01\\dataset01_primary_topic.csv\nValidated: flattened_dataset01\\dataset01__id.csv\nValidated: flattened_dataset01\\dataset01_counts_by_year.csv\nValidated: flattened_dataset01\\dataset01_citation_normalized_percentile.csv\nValidated: flattened_dataset01\\dataset01_cited_by_percentile_year.csv\nValidated: flattened_dataset01\\dataset01_primary_location.csv\nValidated: flattened_dataset01\\dataset01_apc_paid.csv\nValidated: flattened_dataset01\\dataset01_topics.csv\nValidated: flattened_dataset01\\dataset01_dataset.csv\nValidated: flattened_dataset01\\dataset01_best_oa_location.csv\nValidated: flattened_dataset01\\dataset01_ids.csv\nValidated: flattened_dataset01\\dataset01_authorships.csv\nValidated: flattened_dataset01\\dataset01_datasets.csv\nValidated: flattened_dataset01\\dataset01_open_access.csv\nValidated: flattened_dataset01\\dataset01_corresponding_institution_ids.csv\nValidated: flattened_dataset01\\dataset01_biblio.csv\nFinished processing dataset01 — saved to flattened_dataset01\n\n Processing Current Population Survey Food Security Supplement.json → dataset02\nValidated: flattened_dataset02\\dataset02_main.csv\nValidated: flattened_dataset02\\dataset02_corresponding_author_ids.csv\nValidated: flattened_dataset02\\dataset02_grants.csv\nValidated: flattened_dataset02\\dataset02_apc_list.csv\nValidated: flattened_dataset02\\dataset02_indexed_in.csv\nValidated: flattened_dataset02\\dataset02_primary_topic.csv\nValidated: flattened_dataset02\\dataset02__id.csv\nValidated: flattened_dataset02\\dataset02_counts_by_year.csv\nValidated: flattened_dataset02\\dataset02_citation_normalized_percentile.csv\nValidated: flattened_dataset02\\dataset02_cited_by_percentile_year.csv\nValidated: flattened_dataset02\\dataset02_primary_location.csv\nValidated: flattened_dataset02\\dataset02_apc_paid.csv\nValidated: flattened_dataset02\\dataset02_topics.csv\nValidated: flattened_dataset02\\dataset02_dataset.csv\nValidated: flattened_dataset02\\dataset02_best_oa_location.csv\nValidated: flattened_dataset02\\dataset02_ids.csv\nValidated: flattened_dataset02\\dataset02_authorships.csv\nValidated: flattened_dataset02\\dataset02_datasets.csv\nValidated: flattened_dataset02\\dataset02_open_access.csv\nValidated: flattened_dataset02\\dataset02_corresponding_institution_ids.csv\nValidated: flattened_dataset02\\dataset02_biblio.csv\nFinished processing dataset02 — saved to flattened_dataset02\n\n Processing Farm to School Census.json → dataset03\nValidated: flattened_dataset03\\dataset03_main.csv\nValidated: flattened_dataset03\\dataset03_corresponding_author_ids.csv\nValidated: flattened_dataset03\\dataset03_grants.csv\nValidated: flattened_dataset03\\dataset03_apc_list.csv\nValidated: flattened_dataset03\\dataset03_indexed_in.csv\nValidated: flattened_dataset03\\dataset03_primary_topic.csv\nValidated: flattened_dataset03\\dataset03__id.csv\nValidated: flattened_dataset03\\dataset03_counts_by_year.csv\nValidated: flattened_dataset03\\dataset03_citation_normalized_percentile.csv\nValidated: flattened_dataset03\\dataset03_cited_by_percentile_year.csv\nValidated: flattened_dataset03\\dataset03_primary_location.csv\nValidated: flattened_dataset03\\dataset03_apc_paid.csv\nValidated: flattened_dataset03\\dataset03_topics.csv\nValidated: flattened_dataset03\\dataset03_dataset.csv\nValidated: flattened_dataset03\\dataset03_best_oa_location.csv\nValidated: flattened_dataset03\\dataset03_ids.csv\nValidated: flattened_dataset03\\dataset03_authorships.csv\nValidated: flattened_dataset03\\dataset03_open_access.csv\nValidated: flattened_dataset03\\dataset03_corresponding_institution_ids.csv\nValidated: flattened_dataset03\\dataset03_biblio.csv\nFinished processing dataset03 — saved to flattened_dataset03\n\n Processing Information Resources, Inc. (IRI) InfoScan.json → dataset04\nValidated: flattened_dataset04\\dataset04_main.csv\nValidated: flattened_dataset04\\dataset04_corresponding_author_ids.csv\nValidated: flattened_dataset04\\dataset04_grants.csv\nValidated: flattened_dataset04\\dataset04_apc_list.csv\nValidated: flattened_dataset04\\dataset04_indexed_in.csv\nValidated: flattened_dataset04\\dataset04_primary_topic.csv\nValidated: flattened_dataset04\\dataset04__id.csv\nValidated: flattened_dataset04\\dataset04_counts_by_year.csv\nValidated: flattened_dataset04\\dataset04_citation_normalized_percentile.csv\nValidated: flattened_dataset04\\dataset04_cited_by_percentile_year.csv\nValidated: flattened_dataset04\\dataset04_primary_location.csv\nValidated: flattened_dataset04\\dataset04_apc_paid.csv\nValidated: flattened_dataset04\\dataset04_topics.csv\nValidated: flattened_dataset04\\dataset04_dataset.csv\nValidated: flattened_dataset04\\dataset04_best_oa_location.csv\nValidated: flattened_dataset04\\dataset04_ids.csv\nValidated: flattened_dataset04\\dataset04_authorships.csv\nValidated: flattened_dataset04\\dataset04_open_access.csv\nValidated: flattened_dataset04\\dataset04_corresponding_institution_ids.csv\nValidated: flattened_dataset04\\dataset04_biblio.csv\nFinished processing dataset04 — saved to flattened_dataset04\n\n Processing NASS Census of Agriculture.json → dataset05\nValidated: flattened_dataset05\\dataset05_main.csv\nValidated: flattened_dataset05\\dataset05_corresponding_author_ids.csv\nValidated: flattened_dataset05\\dataset05_grants.csv\nValidated: flattened_dataset05\\dataset05_apc_list.csv\nValidated: flattened_dataset05\\dataset05_indexed_in.csv\nValidated: flattened_dataset05\\dataset05_primary_topic.csv\nValidated: flattened_dataset05\\dataset05__id.csv\nValidated: flattened_dataset05\\dataset05_counts_by_year.csv\nValidated: flattened_dataset05\\dataset05_citation_normalized_percentile.csv\nValidated: flattened_dataset05\\dataset05_cited_by_percentile_year.csv\nValidated: flattened_dataset05\\dataset05_primary_location.csv\nValidated: flattened_dataset05\\dataset05_apc_paid.csv\nValidated: flattened_dataset05\\dataset05_topics.csv\nValidated: flattened_dataset05\\dataset05_dataset.csv\nValidated: flattened_dataset05\\dataset05_best_oa_location.csv\nValidated: flattened_dataset05\\dataset05_ids.csv\nValidated: flattened_dataset05\\dataset05_versions.csv\nValidated: flattened_dataset05\\dataset05_authorships.csv\nValidated: flattened_dataset05\\dataset05_datasets.csv\nValidated: flattened_dataset05\\dataset05_open_access.csv\nValidated: flattened_dataset05\\dataset05_corresponding_institution_ids.csv\nValidated: flattened_dataset05\\dataset05_biblio.csv\nFinished processing dataset05 — saved to flattened_dataset05\n\n Processing RUCC.json → dataset06\nValidated: flattened_dataset06\\dataset06_main.csv\nValidated: flattened_dataset06\\dataset06_corresponding_author_ids.csv\nValidated: flattened_dataset06\\dataset06_grants.csv\nValidated: flattened_dataset06\\dataset06_apc_list.csv\nValidated: flattened_dataset06\\dataset06_indexed_in.csv\nValidated: flattened_dataset06\\dataset06_primary_topic.csv\nValidated: flattened_dataset06\\dataset06__id.csv\nValidated: flattened_dataset06\\dataset06_counts_by_year.csv\nValidated: flattened_dataset06\\dataset06_citation_normalized_percentile.csv\nValidated: flattened_dataset06\\dataset06_cited_by_percentile_year.csv\nValidated: flattened_dataset06\\dataset06_primary_location.csv\nValidated: flattened_dataset06\\dataset06_apc_paid.csv\nValidated: flattened_dataset06\\dataset06_topics.csv\nValidated: flattened_dataset06\\dataset06_dataset.csv\nValidated: flattened_dataset06\\dataset06_best_oa_location.csv\nValidated: flattened_dataset06\\dataset06_ids.csv\nValidated: flattened_dataset06\\dataset06_authorships.csv\nValidated: flattened_dataset06\\dataset06_open_access.csv\nValidated: flattened_dataset06\\dataset06_corresponding_institution_ids.csv\nValidated: flattened_dataset06\\dataset06_biblio.csv\nFinished processing dataset06 — saved to flattened_dataset06\n\n Processing Tenure, ownership, and transition of agricultural land.json → dataset07\nValidated: flattened_dataset07\\dataset07_main.csv\nValidated: flattened_dataset07\\dataset07_corresponding_author_ids.csv\nValidated: flattened_dataset07\\dataset07_grants.csv\nValidated: flattened_dataset07\\dataset07_apc_list.csv\nValidated: flattened_dataset07\\dataset07_indexed_in.csv\nValidated: flattened_dataset07\\dataset07_primary_topic.csv\nValidated: flattened_dataset07\\dataset07__id.csv\nValidated: flattened_dataset07\\dataset07_counts_by_year.csv\nValidated: flattened_dataset07\\dataset07_citation_normalized_percentile.csv\nValidated: flattened_dataset07\\dataset07_cited_by_percentile_year.csv\nValidated: flattened_dataset07\\dataset07_primary_location.csv\nValidated: flattened_dataset07\\dataset07_apc_paid.csv\nValidated: flattened_dataset07\\dataset07_topics.csv\nValidated: flattened_dataset07\\dataset07_dataset.csv\nValidated: flattened_dataset07\\dataset07_best_oa_location.csv\nValidated: flattened_dataset07\\dataset07_ids.csv\nValidated: flattened_dataset07\\dataset07_authorships.csv\nValidated: flattened_dataset07\\dataset07_open_access.csv\nValidated: flattened_dataset07\\dataset07_corresponding_institution_ids.csv\nValidated: flattened_dataset07\\dataset07_biblio.csv\nFinished processing dataset07 — saved to flattened_dataset07\n\n Processing food access research atlas.json → dataset08\nValidated: flattened_dataset08\\dataset08_main.csv\nValidated: flattened_dataset08\\dataset08_corresponding_author_ids.csv\nValidated: flattened_dataset08\\dataset08_grants.csv\nValidated: flattened_dataset08\\dataset08_apc_list.csv\nValidated: flattened_dataset08\\dataset08_indexed_in.csv\nValidated: flattened_dataset08\\dataset08_primary_topic.csv\nValidated: flattened_dataset08\\dataset08__id.csv\nValidated: flattened_dataset08\\dataset08_counts_by_year.csv\nValidated: flattened_dataset08\\dataset08_citation_normalized_percentile.csv\nValidated: flattened_dataset08\\dataset08_cited_by_percentile_year.csv\nValidated: flattened_dataset08\\dataset08_primary_location.csv\nValidated: flattened_dataset08\\dataset08_apc_paid.csv\nValidated: flattened_dataset08\\dataset08_topics.csv\nValidated: flattened_dataset08\\dataset08_dataset.csv\nValidated: flattened_dataset08\\dataset08_best_oa_location.csv\nValidated: flattened_dataset08\\dataset08_ids.csv\nValidated: flattened_dataset08\\dataset08_authorships.csv\nValidated: flattened_dataset08\\dataset08_open_access.csv\nValidated: flattened_dataset08\\dataset08_corresponding_institution_ids.csv\nValidated: flattened_dataset08\\dataset08_biblio.csv\nFinished processing dataset08 — saved to flattened_dataset08\n\n Processing food acquisition and purchase survey.json → dataset09\nValidated: flattened_dataset09\\dataset09_main.csv\nValidated: flattened_dataset09\\dataset09_corresponding_author_ids.csv\nValidated: flattened_dataset09\\dataset09_grants.csv\nValidated: flattened_dataset09\\dataset09_apc_list.csv\nValidated: flattened_dataset09\\dataset09_indexed_in.csv\nValidated: flattened_dataset09\\dataset09_primary_topic.csv\nValidated: flattened_dataset09\\dataset09__id.csv\nValidated: flattened_dataset09\\dataset09_counts_by_year.csv\nValidated: flattened_dataset09\\dataset09_citation_normalized_percentile.csv\nValidated: flattened_dataset09\\dataset09_cited_by_percentile_year.csv\nValidated: flattened_dataset09\\dataset09_primary_location.csv\nValidated: flattened_dataset09\\dataset09_apc_paid.csv\nValidated: flattened_dataset09\\dataset09_topics.csv\nValidated: flattened_dataset09\\dataset09_dataset.csv\nValidated: flattened_dataset09\\dataset09_best_oa_location.csv\nValidated: flattened_dataset09\\dataset09_ids.csv\nValidated: flattened_dataset09\\dataset09_authorships.csv\nValidated: flattened_dataset09\\dataset09_datasets.csv\nValidated: flattened_dataset09\\dataset09_open_access.csv\nValidated: flattened_dataset09\\dataset09_corresponding_institution_ids.csv\nValidated: flattened_dataset09\\dataset09_biblio.csv\nFinished processing dataset09 — saved to flattened_dataset09\n\n Processing household food security survey module.json → dataset10\nValidated: flattened_dataset10\\dataset10_main.csv\nValidated: flattened_dataset10\\dataset10_corresponding_author_ids.csv\nValidated: flattened_dataset10\\dataset10_grants.csv\nValidated: flattened_dataset10\\dataset10_apc_list.csv\nValidated: flattened_dataset10\\dataset10_indexed_in.csv\nValidated: flattened_dataset10\\dataset10_primary_topic.csv\nValidated: flattened_dataset10\\dataset10__id.csv\nValidated: flattened_dataset10\\dataset10_counts_by_year.csv\nValidated: flattened_dataset10\\dataset10_citation_normalized_percentile.csv\nValidated: flattened_dataset10\\dataset10_cited_by_percentile_year.csv\nValidated: flattened_dataset10\\dataset10_primary_location.csv\nValidated: flattened_dataset10\\dataset10_apc_paid.csv\nValidated: flattened_dataset10\\dataset10_topics.csv\nValidated: flattened_dataset10\\dataset10_dataset.csv\nValidated: flattened_dataset10\\dataset10_best_oa_location.csv\nValidated: flattened_dataset10\\dataset10_ids.csv\nValidated: flattened_dataset10\\dataset10_authorships.csv\nValidated: flattened_dataset10\\dataset10_datasets.csv\nValidated: flattened_dataset10\\dataset10_open_access.csv\nValidated: flattened_dataset10\\dataset10_corresponding_institution_ids.csv\nValidated: flattened_dataset10\\dataset10_biblio.csv\nFinished processing dataset10 — saved to flattened_dataset10\n\n Processing local food marketing practices survey.json → dataset11\nValidated: flattened_dataset11\\dataset11_main.csv\nValidated: flattened_dataset11\\dataset11_corresponding_author_ids.csv\nValidated: flattened_dataset11\\dataset11_grants.csv\nValidated: flattened_dataset11\\dataset11_apc_list.csv\nValidated: flattened_dataset11\\dataset11_indexed_in.csv\nValidated: flattened_dataset11\\dataset11_primary_topic.csv\nValidated: flattened_dataset11\\dataset11__id.csv\nValidated: flattened_dataset11\\dataset11_counts_by_year.csv\nValidated: flattened_dataset11\\dataset11_citation_normalized_percentile.csv\nValidated: flattened_dataset11\\dataset11_cited_by_percentile_year.csv\nValidated: flattened_dataset11\\dataset11_primary_location.csv\nValidated: flattened_dataset11\\dataset11_apc_paid.csv\nValidated: flattened_dataset11\\dataset11_topics.csv\nValidated: flattened_dataset11\\dataset11_dataset.csv\nValidated: flattened_dataset11\\dataset11_best_oa_location.csv\nValidated: flattened_dataset11\\dataset11_ids.csv\nValidated: flattened_dataset11\\dataset11_authorships.csv\nValidated: flattened_dataset11\\dataset11_open_access.csv\nValidated: flattened_dataset11\\dataset11_corresponding_institution_ids.csv\nValidated: flattened_dataset11\\dataset11_biblio.csv\nFinished processing dataset11 — saved to flattened_dataset11\n\n Processing quarterly food at home price database.json → dataset12\nValidated: flattened_dataset12\\dataset12_main.csv\nValidated: flattened_dataset12\\dataset12_corresponding_author_ids.csv\nValidated: flattened_dataset12\\dataset12_grants.csv\nValidated: flattened_dataset12\\dataset12_apc_list.csv\nValidated: flattened_dataset12\\dataset12_indexed_in.csv\nValidated: flattened_dataset12\\dataset12_primary_topic.csv\nValidated: flattened_dataset12\\dataset12__id.csv\nValidated: flattened_dataset12\\dataset12_counts_by_year.csv\nValidated: flattened_dataset12\\dataset12_citation_normalized_percentile.csv\nValidated: flattened_dataset12\\dataset12_cited_by_percentile_year.csv\nValidated: flattened_dataset12\\dataset12_primary_location.csv\nValidated: flattened_dataset12\\dataset12_apc_paid.csv\nValidated: flattened_dataset12\\dataset12_topics.csv\nValidated: flattened_dataset12\\dataset12_dataset.csv\nValidated: flattened_dataset12\\dataset12_best_oa_location.csv\nValidated: flattened_dataset12\\dataset12_ids.csv\nValidated: flattened_dataset12\\dataset12_authorships.csv\nValidated: flattened_dataset12\\dataset12_open_access.csv\nValidated: flattened_dataset12\\dataset12_corresponding_institution_ids.csv\nValidated: flattened_dataset12\\dataset12_biblio.csv\nFinished processing dataset12 — saved to flattened_dataset12\n\n Processing transition of agricultural land survey.json → dataset13\nValidated: flattened_dataset13\\dataset13_main.csv\nValidated: flattened_dataset13\\dataset13_corresponding_author_ids.csv\nValidated: flattened_dataset13\\dataset13_grants.csv\nValidated: flattened_dataset13\\dataset13_apc_list.csv\nValidated: flattened_dataset13\\dataset13_indexed_in.csv\nValidated: flattened_dataset13\\dataset13_primary_topic.csv\nValidated: flattened_dataset13\\dataset13__id.csv\nValidated: flattened_dataset13\\dataset13_counts_by_year.csv\nValidated: flattened_dataset13\\dataset13_citation_normalized_percentile.csv\nValidated: flattened_dataset13\\dataset13_cited_by_percentile_year.csv\nValidated: flattened_dataset13\\dataset13_primary_location.csv\nValidated: flattened_dataset13\\dataset13_apc_paid.csv\nValidated: flattened_dataset13\\dataset13_topics.csv\nValidated: flattened_dataset13\\dataset13_dataset.csv\nValidated: flattened_dataset13\\dataset13_best_oa_location.csv\nValidated: flattened_dataset13\\dataset13_ids.csv\nValidated: flattened_dataset13\\dataset13_authorships.csv\nValidated: flattened_dataset13\\dataset13_open_access.csv\nValidated: flattened_dataset13\\dataset13_corresponding_institution_ids.csv\nValidated: flattened_dataset13\\dataset13_biblio.csv\nFinished processing dataset13 — saved to flattened_dataset13"
  },
  {
    "objectID": "code/flatten_openalex_all_datasets.html#generate-a-schema-diagram",
    "href": "code/flatten_openalex_all_datasets.html#generate-a-schema-diagram",
    "title": "Looped over all datasets",
    "section": "1 Generate a Schema Diagram",
    "text": "1 Generate a Schema Diagram\n\npip install graphviz\n\nRequirement already satisfied: graphviz in c:\\users\\lachenar\\appdata\\local\\anaconda3\\lib\\site-packages (0.20.3)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport os\nos.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\Graphviz\\bin\"\n\nimport shutil\nprint(shutil.which(\"dot\"))  # Should now return the full path\n\nC:\\Program Files\\Graphviz\\bin\\dot.EXE\n\n\n\nimport pandas as pd\nfrom graphviz import Digraph\n\n# Set directory where flattened outputs are\nbase_dir = \".\"  # or full path\n\n# Get all dataset folders\ndataset_folders = [f for f in os.listdir(base_dir) if f.startswith(\"flattened_dataset\")]\n\n# Loop through each dataset\nfor dataset_folder in dataset_folders:\n    print(f\"Building schema for {dataset_folder}\")\n    dot = Digraph(comment=f\"Schema: {dataset_folder}\", format=\"png\")\n    dot.attr(rankdir=\"LR\")\n\n    csv_files = [f for f in os.listdir(dataset_folder) if f.endswith(\".csv\")]\n\n    tables = {}\n\n    for csv_file in csv_files:\n        table_name = csv_file.replace(\".csv\", \"\")\n        path = os.path.join(dataset_folder, csv_file)\n\n        # Read only first few rows for speed\n        df = pd.read_csv(path, nrows=500)\n\n        # Summarize schema\n        col_lines = []\n        max_cols = 10  # show up to 10 fields\n        for i, col in enumerate(df.columns[:max_cols]):\n            dtype = str(df[col].dtype)\n            col_lines.append(f\"{col} : {dtype}\")\n        if len(df.columns) &gt; max_cols:\n            col_lines.append(\"...\")  # indicate there's more\n\n        table_def = f\"{{{table_name}|{'\\\\l'.join(col_lines)}\\\\l}}\"\n\n        # Store\n        tables[table_name] = {\n            \"cols\": df.columns.tolist(),\n            \"definition\": table_def\n        }\n        dot.node(table_name, label=table_def, shape=\"record\")\n\n    # Draw relationships (parent_id → id)\n    for table_name, info in tables.items():\n        cols = info[\"cols\"]\n        if \"parent_id\" in cols:\n            dot.edge(table_name, f\"{dataset_folder}_main\", label=\"parent_id → id\")\n\n    # Save diagram\n    output_path = os.path.join(dataset_folder, f\"{dataset_folder}_schema\")\n    dot.render(output_path, cleanup=True)\n    print(f\"Saved schema diagram to {output_path}.png\")\n\n\nimport os\nimport pandas as pd\n\n# Path to the dataset folder (e.g., flattened_dataset01)\ndataset_folder = \"flattened_dataset01\"\ndataset_id = \"dataset01\"  # used to build column links\n\nschema_rows = []\n\n# Loop through each CSV file\nfor csv_file in os.listdir(dataset_folder):\n    if csv_file.endswith(\".csv\"):\n        table_name = csv_file.replace(\".csv\", \"\")\n        file_path = os.path.join(dataset_folder, csv_file)\n\n        # Read a sample of rows\n        df = pd.read_csv(file_path, nrows=100)\n\n        for col in df.columns:\n            dtype = str(df[col].dtype)\n\n            # Determine lookup logic\n            if col == \"id\" and \"main\" in table_name:\n                is_lookup = \"PRIMARY KEY\"\n            elif col == \"parent_id\":\n                is_lookup = f\"FOREIGN KEY → {dataset_id}_main.id\"\n            else:\n                is_lookup = \"\"\n\n            schema_rows.append({\n                \"table_name\": table_name,\n                \"column_name\": col,\n                \"data_type\": dtype,\n                \"is_lookup\": is_lookup\n            })\n\n# Save schema summary to CSV\nschema_df = pd.DataFrame(schema_rows)\nschema_df.to_csv(f\"{dataset_folder}_schema_summary.csv\", index=False)\n\nprint(f\"Saved schema summary to {dataset_folder}_schema_summary.csv\")\n\nSaved schema summary to flattened_dataset01_schema_summary.csv"
  },
  {
    "objectID": "appendices/workflow.html",
    "href": "appendices/workflow.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The project workflow outlines the steps involved to evaluate how different citation databases track USDA dataset mentions in research papers. In searching for dataset mentions, the goal is to identify a set of publications that can be compared across the citation database test cases.\n\nThe process of deriving the list of publications from a citation database consists of four steps. Each step produces an output which is used as the input for the following step:\n\n\n\nIdentify USDA datasets that will be searched for and tracked.\nCollect official dataset names along with common abbreviations, acronyms, and alternative references used.\n\nResult: A structured list of dataset names and aliases.\n\n\n\n\nConduct searches across citation databases using multiple methods:\n\nFull-Text (String) Search: Scan entire articles for relevant dataset names.\nReference Search: Identify dataset citations within publication references.\nMachine Learning Models: Apply Kaggle competition models trained to detect dataset mentions.\n\n\nNote: In cases where full-text search is not supported by the citation database API (e.g., Scopus), an initial seed corpus of publications was collected separately to train machine learning models. Refer to “Creating a Seed Corpus” for more details.\nResult: Publication dataset for each data asset across each citation database.\n\n\n\n\nPre-process and clean publication metadata generated from each citation database.\nStandardize journal, institution, and author names.\nDeduplicate records.\n\nResult: Cleaned publication metadata, removed of duplicates, inconsistencies, and missing information.\n\n\n\n\nCompare dataset coverage across Scopus, OpenAlex, and Dimensions.\nApply fuzzy matching techniques to identify overlapping and unique dataset mentions.\nAnalyze differences in journal coverage, citation patterns, and author affiliations.\n\nResult: A set of statistics used to evaluate dataset tracking accuracy.",
    "crumbs": [
      "Appendices",
      "Workflow"
    ]
  },
  {
    "objectID": "appendices/workflow.html#define-scope-of-data-assets-to-be-searched",
    "href": "appendices/workflow.html#define-scope-of-data-assets-to-be-searched",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Identify USDA datasets that will be searched for and tracked.\nCollect official dataset names along with common abbreviations, acronyms, and alternative references used.\n\nResult: A structured list of dataset names and aliases.",
    "crumbs": [
      "Appendices",
      "Workflow"
    ]
  },
  {
    "objectID": "appendices/workflow.html#extract-dataset-mentions-from-publications",
    "href": "appendices/workflow.html#extract-dataset-mentions-from-publications",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Conduct searches across citation databases using multiple methods:\n\nFull-Text (String) Search: Scan entire articles for relevant dataset names.\nReference Search: Identify dataset citations within publication references.\nMachine Learning Models: Apply Kaggle competition models trained to detect dataset mentions.\n\n\nNote: In cases where full-text search is not supported by the citation database API (e.g., Scopus), an initial seed corpus of publications was collected separately to train machine learning models. Refer to “Creating a Seed Corpus” for more details.\nResult: Publication dataset for each data asset across each citation database.",
    "crumbs": [
      "Appendices",
      "Workflow"
    ]
  },
  {
    "objectID": "appendices/workflow.html#pre-process-and-clean-publication-datasets",
    "href": "appendices/workflow.html#pre-process-and-clean-publication-datasets",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Pre-process and clean publication metadata generated from each citation database.\nStandardize journal, institution, and author names.\nDeduplicate records.\n\nResult: Cleaned publication metadata, removed of duplicates, inconsistencies, and missing information.",
    "crumbs": [
      "Appendices",
      "Workflow"
    ]
  },
  {
    "objectID": "appendices/workflow.html#compare-across-citation-databases",
    "href": "appendices/workflow.html#compare-across-citation-databases",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Compare dataset coverage across Scopus, OpenAlex, and Dimensions.\nApply fuzzy matching techniques to identify overlapping and unique dataset mentions.\nAnalyze differences in journal coverage, citation patterns, and author affiliations.\n\nResult: A set of statistics used to evaluate dataset tracking accuracy.",
    "crumbs": [
      "Appendices",
      "Workflow"
    ]
  },
  {
    "objectID": "appendices/workflow/step03/04scopus.html",
    "href": "appendices/workflow/step03/04scopus.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "To analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON"
  },
  {
    "objectID": "appendices/workflow/step03/04scopus.html#scopus",
    "href": "appendices/workflow/step03/04scopus.html#scopus",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "To analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON"
  },
  {
    "objectID": "appendices/workflow/step02_02/02scopus.html",
    "href": "appendices/workflow/step02_02/02scopus.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later."
  },
  {
    "objectID": "appendices/workflow/step02_02/02scopus.html#scopus",
    "href": "appendices/workflow/step02_02/02scopus.html#scopus",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later."
  },
  {
    "objectID": "appendices/workflow/step02_02/02dimensions.html",
    "href": "appendices/workflow/step02_02/02dimensions.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The seed corpus approach was only applied to Scopus and OpenAlex."
  },
  {
    "objectID": "appendices/workflow/step02_02/02dimensions.html#dimensions",
    "href": "appendices/workflow/step02_02/02dimensions.html#dimensions",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The seed corpus approach was only applied to Scopus and OpenAlex."
  },
  {
    "objectID": "appendices/workflow/step02_01/03scopus.html",
    "href": "appendices/workflow/step02_01/03scopus.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases."
  },
  {
    "objectID": "appendices/workflow/step02_01/03scopus.html#scopus",
    "href": "appendices/workflow/step02_01/03scopus.html#scopus",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases."
  },
  {
    "objectID": "appendices/workflow/step02_01/03scopus.html#footnotes",
    "href": "appendices/workflow/step02_01/03scopus.html#footnotes",
    "title": "Citation Database Assessment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExplanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.↩︎\nExplanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.↩︎"
  },
  {
    "objectID": "appendices/workflow/step02_01/03dimensions.html",
    "href": "appendices/workflow/step02_01/03dimensions.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "To identify publications mentioning USDA datasets, we used the Dimensions.ai API, following the same general methodology applied in Scopus and OpenAlex. We reused the same dataset aliases, institutional flag terms, and overall search criteria to ensure consistency across sources. The search covered scholarly publications from 2017 to 2023 and was restricted to works authored by at least one researcher affiliated with a U.S.-based institution.\nDimensions queries are written using a structured Domain Specific Language (DSL). We constructed boolean queries that combined multiple dataset aliases (e.g., “NASS Census of Agriculture”, “USDA Census”, “Agricultural Census”) with institutional identifiers (e.g., “USDA”, “NASS”, “U.S. Department of Agriculture”). As with Scopus and OpenAlex, both a dataset alias and an institutional flag term were required to appear in each result. These terms were grouped using OR within each category and then combined with an AND across categories. For example:\n\n(“NASS Census of Agriculture” OR “Census of Agriculture” OR “USDA Census of Agriculture” OR “Agricultural Census” OR “USDA Census” OR “AG Census”) AND (USDA OR “US Department of Agriculture” OR “United States Department of Agriculture” OR NASS OR “National Agricultural Statistics Service”)\n\nWe implemented this process using the dimcli Python library, which provides a streamlined interface to the Dimensions.ai API and automates result pagination. A significant advantage of this approach is the capability of the Dimensions.ai platform to manage complex searches directly, resulting in precise results and reduced computational overhead. By executing these queries directly through the API, we avoided the technical complexity associated with downloading and locally processing large amounts of textual content. Moreover, the Dimensions.ai API results can be automatically structured into an analysis-ready DataFrame format. This simplified data structure greatly facilitated our subsequent validation, data integration, and analytical workflows.\nTo maintain methodological consistency with Scopus and OpenAlex, the following filters were applied to the search:\n\nEnglish-language publications\nWorks published between 2017-2023\nDocument types: articles, chapters, proceedings, monographs, and preprints\nAuthor affiliations: Publications were filtered to include only those authored by researchers affiliated with at least one U.S.-based institution.\n\nFor comparability with the Scopus and OpenAlex samples, only publications classified as “articles” were retained for final analysis. This restriction reduces duplication across versions (e.g., preprints, proceedings) and reflects our focus on peer-reviewed scholarly output.\nFor each article, we retrieved metadata including title, authors, DOI, journal, abstract, publication date, citation counts, subject classifications, and links. These fields supported topic-level analysis, author and institution mapping, and validation of dataset mentions.\nUsing Dimensions.ai provided two main technical advantages. First, because the platform supports full-text query execution natively, we avoided the need to download or parse external files. Second, the API responses were easily converted into analysis-ready DataFrames, which simplified downstream validation and integration with other sources."
  },
  {
    "objectID": "appendices/workflow/step02_01/03dimensions.html#dimensions",
    "href": "appendices/workflow/step02_01/03dimensions.html#dimensions",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "To identify publications mentioning USDA datasets, we used the Dimensions.ai API, following the same general methodology applied in Scopus and OpenAlex. We reused the same dataset aliases, institutional flag terms, and overall search criteria to ensure consistency across sources. The search covered scholarly publications from 2017 to 2023 and was restricted to works authored by at least one researcher affiliated with a U.S.-based institution.\nDimensions queries are written using a structured Domain Specific Language (DSL). We constructed boolean queries that combined multiple dataset aliases (e.g., “NASS Census of Agriculture”, “USDA Census”, “Agricultural Census”) with institutional identifiers (e.g., “USDA”, “NASS”, “U.S. Department of Agriculture”). As with Scopus and OpenAlex, both a dataset alias and an institutional flag term were required to appear in each result. These terms were grouped using OR within each category and then combined with an AND across categories. For example:\n\n(“NASS Census of Agriculture” OR “Census of Agriculture” OR “USDA Census of Agriculture” OR “Agricultural Census” OR “USDA Census” OR “AG Census”) AND (USDA OR “US Department of Agriculture” OR “United States Department of Agriculture” OR NASS OR “National Agricultural Statistics Service”)\n\nWe implemented this process using the dimcli Python library, which provides a streamlined interface to the Dimensions.ai API and automates result pagination. A significant advantage of this approach is the capability of the Dimensions.ai platform to manage complex searches directly, resulting in precise results and reduced computational overhead. By executing these queries directly through the API, we avoided the technical complexity associated with downloading and locally processing large amounts of textual content. Moreover, the Dimensions.ai API results can be automatically structured into an analysis-ready DataFrame format. This simplified data structure greatly facilitated our subsequent validation, data integration, and analytical workflows.\nTo maintain methodological consistency with Scopus and OpenAlex, the following filters were applied to the search:\n\nEnglish-language publications\nWorks published between 2017-2023\nDocument types: articles, chapters, proceedings, monographs, and preprints\nAuthor affiliations: Publications were filtered to include only those authored by researchers affiliated with at least one U.S.-based institution.\n\nFor comparability with the Scopus and OpenAlex samples, only publications classified as “articles” were retained for final analysis. This restriction reduces duplication across versions (e.g., preprints, proceedings) and reflects our focus on peer-reviewed scholarly output.\nFor each article, we retrieved metadata including title, authors, DOI, journal, abstract, publication date, citation counts, subject classifications, and links. These fields supported topic-level analysis, author and institution mapping, and validation of dataset mentions.\nUsing Dimensions.ai provided two main technical advantages. First, because the platform supports full-text query execution natively, we avoided the need to download or parse external files. Second, the API responses were easily converted into analysis-ready DataFrames, which simplified downstream validation and integration with other sources."
  },
  {
    "objectID": "appendices/workflow/results/compare_pub_data.html",
    "href": "appendices/workflow/results/compare_pub_data.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to develop statistics that measure dataset tracking accuracy.\n\n\n\n\nContinuing with our case study, we use the datasets produced in Step 4 to produce counts of the number of journals with Ag Census publications that:\n\nonly appear in Scopus,\nonly appear in OpenAlex, or\nappear in both.\n\nFor journals that contain Ag Census data in both citation databases, we summarize the coverage of publications that appear in both Scopus and OpenAlex.\nThen, we investigate discrepancies based on factors like missing identifiers, mismatched journal information (ISSNs), and additional publications accessed through OpenAlex’s API.\nAdd here: What are the steps in producing Table AA\n\nScopusOpenAlex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section presents results after matching (which type varies – deterministic vs fuzzy)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of Matching Methods\n\n\n\n\n\n\nRule-based matching for exact matches\nProbabilistic matching for handling variations\nMachine learning methods for complex cases\n\n\n\n\nTable 1: Summary of Methods\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nConsiderations\nExample\nPros\nCons\n\n\n\n\nSearching for dataset names within Scopus\n\n\n\n\n\n\nSearching for dataset names within OpenAlex\n“Location” field set to “journal”\n\n\n\n\n\nDisambiguation of authors\n\n\n\n\n\n\nDisambiguation of institutions\n\n\n\n\n\n\nStandardization of institutions\n\n\n\n\n\n\nSearching based on the frequency of dataset appearance in journals\n\n\n\n\n\n\nMORE . . .\n\n\n\n\n\n\nFiltering on keywords to determine themes\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll appendices referenced throughout the report are located on this page."
  },
  {
    "objectID": "appendices/workflow/results/compare_pub_data.html#sec-matching",
    "href": "appendices/workflow/results/compare_pub_data.html#sec-matching",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to develop statistics that measure dataset tracking accuracy.\n\n\n\n\nContinuing with our case study, we use the datasets produced in Step 4 to produce counts of the number of journals with Ag Census publications that:\n\nonly appear in Scopus,\nonly appear in OpenAlex, or\nappear in both.\n\nFor journals that contain Ag Census data in both citation databases, we summarize the coverage of publications that appear in both Scopus and OpenAlex.\nThen, we investigate discrepancies based on factors like missing identifiers, mismatched journal information (ISSNs), and additional publications accessed through OpenAlex’s API.\nAdd here: What are the steps in producing Table AA\n\nScopusOpenAlex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section presents results after matching (which type varies – deterministic vs fuzzy)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of Matching Methods\n\n\n\n\n\n\nRule-based matching for exact matches\nProbabilistic matching for handling variations\nMachine learning methods for complex cases\n\n\n\n\nTable 1: Summary of Methods\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nConsiderations\nExample\nPros\nCons\n\n\n\n\nSearching for dataset names within Scopus\n\n\n\n\n\n\nSearching for dataset names within OpenAlex\n“Location” field set to “journal”\n\n\n\n\n\nDisambiguation of authors\n\n\n\n\n\n\nDisambiguation of institutions\n\n\n\n\n\n\nStandardization of institutions\n\n\n\n\n\n\nSearching based on the frequency of dataset appearance in journals\n\n\n\n\n\n\nMORE . . .\n\n\n\n\n\n\nFiltering on keywords to determine themes\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll appendices referenced throughout the report are located on this page."
  },
  {
    "objectID": "appendices/app_scopus.html",
    "href": "appendices/app_scopus.html",
    "title": "Scopus Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md"
  },
  {
    "objectID": "appendices/app_scopus.html#sec-app-scopus",
    "href": "appendices/app_scopus.html#sec-app-scopus",
    "title": "Scopus Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md"
  },
  {
    "objectID": "appendices/app_scopus.html#data-dictionary",
    "href": "appendices/app_scopus.html#data-dictionary",
    "title": "Scopus Data Dictionary",
    "section": "Data Dictionary",
    "text": "Data Dictionary\n\n\n\n\n\n\nDownload Scopus Source Files\n\n\n\nYou can download the source files from this link.\n\n\n\npublication.csv (Primary table)\n\nDescription: Central table with metadata about publications.\nColumns:\n\nid: Unique publication identifier\ntitle: Publication title\ndoi: Digital Object Identifier\nyear, month: Date of publication\ncitation_count, pub_type: Additional metadata\n\n\n\n\ndataset_alias.csv\n\nDescription: Lists dataset aliases (alternate names).\nColumns:\n\nalias_id: Unique alias identifier\nparent_alias_id: Primary alias identifier (if alias_id = parent_alias_id, it’s primary)\nalias: Name of the alias\n\nHow to use:\n\nIdentify primary aliases where alias_id = parent_alias_id\nFind all aliases by filtering on parent_alias_id\n\n\n\n\ndyad.csv\n\nDescription: Links publications (publication.csv) and dataset aliases (dataset_alias.csv).\nColumns:\n\nid: Unique identifier for each mention (dyad)\npublication_id: Foreign key to publication.csv\nalias_id: Foreign key to dataset_alias.csv\nmention_candidate: Mention text from publication\n\n\n\n\nmodel.csv\n\nDescription: Lists methods/models for identifying dataset mentions.\nColumns:\n\nid: Unique model identifier\nname: Name of the identification model\n\n\n\n\ndyad_model.csv\n\nDescription: Connects dyads and models used to identify them.\nColumns:\n\ndyad_id: Foreign key to dyad.csv\nmodel_id: Foreign key to model.csv\nscore: Confidence or relevance score\n\nHow to use:\n\nFilter mentions by joining with dyad.csv on dyad_id and filtering by model_id"
  },
  {
    "objectID": "appendices/app_scopus.html#sample-data",
    "href": "appendices/app_scopus.html#sample-data",
    "title": "Scopus Data Dictionary",
    "section": "Sample Data",
    "text": "Sample Data\n\npublication.csvdataset_alias.csvdyad.csvmodel.csvdyad_model.csv\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntitle\ndoi\nyear\nmonth\n\n\n\n\n321613\nNew estimates for CRNA vacancies\n\n2009\n4\n\n\n321614\nCrossing county lines: The impact of crash location and driver’s…\n10.1016/j.aap.2006…\n2006\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nalias_id\nparent_alias_id\nalias\n\n\n\n\n1676\n87\n89\nCensus of Agriculture\n\n\n1673\n12\n282\nARMS Farm Financial and Crop Production Practices\n\n\n\n\n\n\n\n\nid\npublication_id\nalias_id\nmention_candidate\n\n\n\n\n2569\n1211491\n87\ncensus of agriculture\n\n\n2573\n1199598\n88\nusda census of agriculture\n\n\n\n\n\n\n\n\nid\nname\n\n\n\n\n1\nstring_matching\n\n\n5\nrefmatch\n\n\n\n\n\n\n\n\nid\ndyad_id\nmodel_id\nscore\n\n\n\n\n4928\n2569\n1\n2.0\n\n\n4929\n2569\n4\n1.0\n\n\n4930\n2569\n2\n1.0"
  },
  {
    "objectID": "appendices/app_scopus.html#how-to-extract-publications-for-a-specific-dataset",
    "href": "appendices/app_scopus.html#how-to-extract-publications-for-a-specific-dataset",
    "title": "Scopus Data Dictionary",
    "section": "How to Extract Publications for a Specific Dataset",
    "text": "How to Extract Publications for a Specific Dataset\nTo find all publications associated with a particular dataset, such as the NASS Census of Agriculture, follow these steps:\n\nIdentify the Main Alias:\n\nFind the alias_id where alias_id equals parent_alias_id for the dataset.\nFor NASS Census of Agriculture, the main alias has alias_id = 89.\n\nGet All Aliases:\n\nIn dataset_alias.csv, filter rows where parent_alias_id equals 89.\nThis gives you all aliases associated with the NASS Census of Agriculture dataset.\n\nLink Aliases to Publications:\n\nIn dyad.csv, filter rows where alias_id matches any of the alias_ids obtained in step 2.\nThis will give you publication_ids of publications mentioning any alias of the dataset.\n\nRetrieve Publication Details:\n\nUsing the publication_ids from step 3, retrieve the corresponding records from publication.csv."
  },
  {
    "objectID": "appendices/app_scopus.html#filtering-publications-by-specific-models",
    "href": "appendices/app_scopus.html#filtering-publications-by-specific-models",
    "title": "Scopus Data Dictionary",
    "section": "Filtering Publications by Specific Models",
    "text": "Filtering Publications by Specific Models\nSince we’re interested in mentions identified by the string_matching and refmatch models (models with id 1 and 5), follow these steps:\n\nFilter Dyads by Model:\n\nIn dyad_model.csv, filter rows where model_id is 1 or 5.\nThis gives you dyad_ids linked to these models.\n\nGet Relevant Dyads:\n\nPerform an inner join with dyad.csv on dyad_id.\nThis filters dyads to only those identified by the specified models.\n\nProceed as Before:\n\nContinue with the steps in the previous section, but using the filtered dyads from step 2."
  },
  {
    "objectID": "appendices/app_msi.html",
    "href": "appendices/app_msi.html",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "",
    "text": "The Minority-Serving Institutions (MSI) Data captures institutions eligible for federal MSI programs, as determined by the U.S. Department of Education and other sources. In this project, MSI data is used to analyze institutional characteristics in relation to research publications identified in Scopus, OpenAlex, and Dimensions.\nThis dataset provides information on institutions eligible or potentially eligible for at least one MSI designation and includes data from 2017 to 2023. The MSI dataset integrates information from multiple sources and is merged with IPEDS data to track research output across different institution types.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#summary-of-the-msi-data",
    "href": "appendices/app_msi.html#summary-of-the-msi-data",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "Summary of the MSI data",
    "text": "Summary of the MSI data\n\nTotal Institutions by MSI StatusPrivate Institutions by MSI StatusPrivate For-Profit Institutions by MSI StatusPrivate Not-for-Profit Institutions by MSI StatusPublic Institutions by MSI StatusPublic 2-year Institutions by MSI StatusPublic 4-year Institutions by MSI StatusPrivate 2-year Institutions by MSI StatusPrivate 4-year Institutions by MSI Status\n\n\n\n\n\nYear\nTotal\nMSI %\nNot_MSI %\n\n\n\n\n2017\n5242\n8.13\n91.87\n\n\n2018\n5242\n7.69\n92.31\n\n\n2019\n5242\n7.84\n92.16\n\n\n2020\n5242\n7.80\n92.20\n\n\n2021\n5242\n8.81\n91.19\n\n\n2022\n5242\n16.73\n83.27\n\n\n2023\n5242\n16.58\n83.42\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1837\n5.66\n94.34\n\n\n2018\n1837\n5.72\n94.28\n\n\n2019\n1837\n5.72\n94.28\n\n\n2020\n1837\n5.77\n94.23\n\n\n2021\n1837\n5.88\n94.12\n\n\n2022\n1837\n14.81\n85.19\n\n\n2023\n1837\n14.81\n85.19\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1409\n0.00\n100.00\n\n\n2018\n1409\n0.00\n100.00\n\n\n2019\n1409\n0.00\n100.00\n\n\n2020\n1409\n0.00\n100.00\n\n\n2021\n1409\n0.00\n100.00\n\n\n2022\n1409\n0.14\n99.86\n\n\n2023\n1409\n0.21\n99.79\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n26\n0.00\n100.00\n\n\n2018\n26\n0.00\n100.00\n\n\n2019\n26\n0.00\n100.00\n\n\n2020\n26\n0.00\n100.00\n\n\n2021\n26\n0.00\n100.00\n\n\n2022\n26\n3.85\n96.15\n\n\n2023\n26\n3.85\n96.15\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1678\n19.18\n80.81\n\n\n2018\n1678\n17.76\n82.24\n\n\n2019\n1678\n18.24\n81.76\n\n\n2020\n1678\n18.06\n81.94\n\n\n2021\n1678\n21.10\n78.90\n\n\n2022\n1678\n33.86\n66.15\n\n\n2023\n1678\n35.34\n64.66\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n933\n19.72\n80.28\n\n\n2018\n933\n16.93\n83.07\n\n\n2019\n933\n17.04\n82.96\n\n\n2020\n933\n17.15\n82.85\n\n\n2021\n933\n20.15\n79.85\n\n\n2022\n933\n36.66\n63.34\n\n\n2023\n933\n35.05\n64.95\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n807\n17.10\n82.90\n\n\n2018\n807\n17.35\n82.65\n\n\n2019\n807\n18.22\n81.78\n\n\n2020\n807\n17.82\n82.18\n\n\n2021\n807\n20.57\n79.43\n\n\n2022\n807\n32.09\n67.91\n\n\n2023\n807\n32.96\n67.04\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n139\n2.88\n97.12\n\n\n2018\n139\n2.88\n97.12\n\n\n2019\n139\n2.16\n97.84\n\n\n2020\n139\n2.16\n97.84\n\n\n2021\n139\n2.88\n97.12\n\n\n2022\n139\n12.23\n87.77\n\n\n2023\n139\n12.23\n87.77\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1714\n5.83\n94.17\n\n\n2018\n1714\n5.84\n94.16\n\n\n2019\n1714\n5.95\n94.05\n\n\n2020\n1714\n6.01\n93.99\n\n\n2021\n1714\n6.07\n93.93\n\n\n2022\n1714\n14.88\n85.12\n\n\n2023\n1714\n14.88\n85.12",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#data-processing-and-standardization",
    "href": "appendices/app_msi.html#data-processing-and-standardization",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "Data Processing and Standardization",
    "text": "Data Processing and Standardization\n\nVariable Name Changes and Formatting:\n\nyear was added to track MSI status over time.\nUNITID is the primary key to merge MSI and IPEDS datasets.\n\nHandling Missing Data and Filters:\n\nInstitutions without UNITID were excluded.\nNon-relevant columns were removed.\n\nMerging Strategy:\n\nThe 2017-2021 MSI data was directly compatible with IPEDS.\nThe 2022-2023 MSI data required additional formatting before merging.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#how-to-merge-with-ipeds-data",
    "href": "appendices/app_msi.html#how-to-merge-with-ipeds-data",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "How to Merge with IPEDS Data",
    "text": "How to Merge with IPEDS Data\nThe MSI dataset can be linked with IPEDS data using the UNITID and year variables. This allows for:\n\nTracking institutional MSI status over time.\nComparing MSI and non-MSI institutions within Scopus, OpenAlex, and Dimensions.\nAssessing dataset usage patterns across different institution types.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#footnotes",
    "href": "appendices/app_msi.html#footnotes",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 2017-2021 MSI data was sourced from the Minority Serving Institutions (MSI) Data Project by Nguyen et al. (2023), which merges the U.S. Department of Education’s MSI eligibility metrics (2017-2021) with IPEDS data.↩︎\nThe 2022-2023 MSI data was obtained from the Rutgers Graduate School of Education, which maintains annual MSI eligibility lists.↩︎\nThe 2022-2023 MSI data was obtained from the Rutgers Graduate School of Education, which maintains annual MSI eligibility lists.↩︎",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_institutions.html",
    "href": "appendices/app_institutions.html",
    "title": "Cleaning IPEDS and MSI Data",
    "section": "",
    "text": "This appendix documents the construction and visualization of MSI (Minority-Serving Institution) eligibility trends from 2017 to 2023.\nTo create a harmonsized dataset of institutional coverage across datasets, institutional affiliation data associated with each publication’s athor(s) are linked to institutional records using IPEDS identifiers. Linking the publication metadata with IPEDS institutional data adds information not available in the publication affiliation data alone. This additional information includes public or private institution (control), degree level, MSI designation, and geographic location. Special attention is given to coverage of underrepresented institutions and Minority-Serving Institutions (MSIs).\nTo support this linkage, a standardized panel dataset of U.S. higher education institutions was developed, capturing consistent MSI designations over time. Two sources were used: (1) the MSI Data Project (Nguyen et al., 2023) for the years 2017–2021 and (2) Rutgers CMSI for 2022–2023. These datasets were cleaned and merged with IPEDS institutional data, filtered to include only 2- and 4-year institutions in the 50 U.S. states. Data cleaning steps included:\n\nAddressing inconsistencies in eligibility labels,\nRemoving duplicates, and\nCreating summary measures of MSI eligibility by year.\n\nThe resulting visualization below graphs both the number and percent of institutions designated as MSIs over time, with a notable increase observed in 2022. The accompanying plot and source code are available in the IPEDS appendix available here and MSI appendix available here.\n\n  \n\nSource code used to generate graphic: Available here.\n\n\nThis is where the analysis concluded. Future work would need to examine the reasons behind the observed increase in MSI designations, which may reflect changes in classification rules, institutional characteristics, or reporting practices. Additionally, extending the analysis would involve linking these institutional records to the affiliations of publication authors identified across Scopus, OpenAlex, and Dimensions. This would allow for a more detailed examination of which types of institutions, and particularly which MSIs, are represented in dataset-linked research, helping to determine patterns of inclusion, visibility, and institutional participation in federally funded data ecosystems.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data"
    ]
  },
  {
    "objectID": "appendices/app_institutions.html#footnotes",
    "href": "appendices/app_institutions.html#footnotes",
    "title": "Cleaning IPEDS and MSI Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIPEDS appendix available here↩︎\nMSI appendix available here↩︎",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data"
    ]
  },
  {
    "objectID": "appendices/app_dimensions.html",
    "href": "appendices/app_dimensions.html",
    "title": "Dimensions Data Dictionary",
    "section": "",
    "text": "Research partners at the University of Utah have access to Dimensions."
  },
  {
    "objectID": "appendices/app_dimensions.html#sec-app-dimensions",
    "href": "appendices/app_dimensions.html#sec-app-dimensions",
    "title": "Dimensions Data Dictionary",
    "section": "",
    "text": "Research partners at the University of Utah have access to Dimensions."
  },
  {
    "objectID": "appendices/app_crosswalk.html",
    "href": "appendices/app_crosswalk.html",
    "title": "Project Documentation",
    "section": "",
    "text": "All project files are available in our GitHub repository. This section provides additional reference material.",
    "crumbs": [
      "Appendices",
      "Documentation"
    ]
  },
  {
    "objectID": "appendices/app_crosswalk.html#file-inventory",
    "href": "appendices/app_crosswalk.html#file-inventory",
    "title": "Project Documentation",
    "section": "File Inventory",
    "text": "File Inventory\n\nScopus FilesOpenAlex FilesDimensions Files\n\n\n\nPrimary Table: publication\nSupporting Tables:\n\nagency_run\nasjc\nauthor\nauthor_affiliation\ndataset_alias\ndyad\ndyad_model\nissn\njournal\nmodel\npublication_affiliation\npublication_asjc\npublication_author\npublication_topic\npublication_ufc\npublisher\ntopic\n\n\nRefer to the schema for additional column-level details.\n\n\n\nFull Text\n\nPrimary Table: main\nSupporting Tables:\n\n_id\napc_list\napc_paid\nauthorships\nbest_oa_location\nbiblio\ncitation_normalized_percentile\ncited_by_percentile_year\ncorresponding_author_ids\ncorresponding_institution_ids\ncounts_by_year\ndataset\ndatasets\ngrants\nids\nindexed_in\nopen_access\nprimary_location\nprimary_topic\ntopics\n\n\n\n\nSeed Corpus\n\nPrimary Table: main\nSupporting Tables:\n\n\n\n\n\nPrimary Table: main\nSupporting Tables:\n\nThe accompanying schema focuses on the primary linking fields between tables. Due to the large number of columns within each table, only key identifiers are included.",
    "crumbs": [
      "Appendices",
      "Documentation"
    ]
  },
  {
    "objectID": "appendices/app_dyads.html",
    "href": "appendices/app_dyads.html",
    "title": "Data Dyads: Assets and Aliases",
    "section": "",
    "text": "alias_id\nparent_alias_id\nalias\nalias_type\nusda_dataset\n\n\n\n\n12\n282\nARMS Farm Financial and Crop Production Practices\nalias\nagricultural resource management survey\n\n\n21\n282\nAgricultural Resource Management Survey\nalias\nagricultural resource management survey\n\n\n46\n282\nAgricultural Resources Management Survey\nalias\nagricultural resource management survey\n\n\n282\n282\nAgricultural Resource Management Survey (ARMS)\nmain\nagricultural resource management survey\n\n\n283\n282\nFarm Financial and Crop Production Practices (ERS)\nalias\nagricultural resource management survey\n\n\n284\n282\nFarm Income and Financial Forecast (ERS)\nalias\nagricultural resource management survey\n\n\n285\n282\nFarm Household Income and Characteristics (ERS)\nalias\nagricultural resource management survey\n\n\n286\n282\nFarm Income and Wealth Statistics (ERS)\nalias\nagricultural resource management survey\n\n\n287\n282\nFarm Production Expenditures (NASS)\nalias\nagricultural resource management survey\n\n\n288\n282\nAgricultural Resource Management Study\nalias\nagricultural resource management survey\n\n\n289\n282\nAgricultural Resources Management Study\nalias\nagricultural resource management survey\n\n\n87\n89\nCensus of Agriculture\nalias\ncensus of agriculture\n\n\n88\n89\nUSDA Census of Agriculture\nalias\ncensus of agriculture\n\n\n89\n89\nNASS Census of Agriculture\nmain\ncensus of agriculture\n\n\n279\n89\nAgricultural Census\nalias\ncensus of agriculture\n\n\n280\n89\nUSDA Census\nalias\ncensus of agriculture\n\n\n281\n89\nAG Census\nalias\ncensus of agriculture\n\n\n1006002\n1006002\nCurrent Population Survey Food Security Supplement,\nMain\ncurrent population survey food security supplement\n\n\n1006016\n1006002\nCPS-FSS\nAcronym\ncurrent population survey food security supplement\n\n\n1006017\n1006002\nCurrent Population Survey Food Security Supplement\nAlias\ncurrent population survey food security supplement\n\n\n1006003\n1006003\nFarm to School Census, \nMain\nfarm-to-school\n\n\n1006007\n1006007\nfood access research atlas\nMain\nfood access research atlas\n\n\n1006009\n1006009\nhousehold food security survey module\nMain\nhousehold food security survey module\n\n\n1006000\n1006000\nInformation Resources, Inc. (IRI) InfoScan\nMain\ninformation resources, inc.\n\n\n1006001\n1006001\nInformation Resources, Inc. (IRI) Consumer Network Panel\nMain\ninformation resources, inc.\n\n\n1006012\n1006000\nIRI Infoscan\nAlias\ninformation resources, inc.\n\n\n1006013\n1006001\nIRI Consumer Network Panel\nAlias\ninformation resources, inc.\n\n\n1006010\n1006010\nlocal food marketing practices survey\nMain\nlocal food marketing practices survey\n\n\n1006018\n1006010\nLFMPS\nAcronym\nlocal food marketing practices survey\n\n\n1006005\n1006005\nfood acquisition and purchase survey\nMain\nnational household food acquisition\n\n\n1006014\n1006005\nFoodAPS\nAcronym\nnational household food acquisition\n\n\n1006006\n1006006\nquarterly food at home price database\nMain\nquarterly food at home price database\n\n\n1006015\n1006006\nQFAHPD\nAcronym\nquarterly food at home price database\n\n\n1007000\n1007000\nRUCC\nmain\nrural-urban continuum codes\n\n\n1007001\n1007000\nRural-Urban Continuum Codes\nalias\nrural-urban continuum codes\n\n\n1007002\n1007000\nRural Urban Continuum Codes\nalias\nrural-urban continuum codes\n\n\n1007003\n1007000\nhttps://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx\nalias\nrural-urban continuum codes\n\n\n1006019\n1006019\nTenure, ownership, and transition of agricultural land\nAlias\ntenure, ownership, and transition of agricultural land\n\n\n1006011\n1006011\ntransition of agricultural land survey\nMain\ntransition of agricultural land survey"
  },
  {
    "objectID": "appendices/app_ipeds.html",
    "href": "appendices/app_ipeds.html",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "",
    "text": "The Integrated Postsecondary Education Data System (IPEDS) is a national dataset maintained by the National Center for Education Statistics (NCES). It collects data from all U.S. institutions participating in federal financial aid programs. In this project, IPEDS data is used to analyze institutional characteristics (e.g., size, classification, location, and financial indicators) in relation to research publications identified in Scopus, OpenAlex, and Dimensions.\nThe raw IPEDS data was obtained from the IPEDS website: IPEDS Data Center.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html#summary-of-the-ipeds-data",
    "href": "appendices/app_ipeds.html#summary-of-the-ipeds-data",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "Summary of the IPEDS Data",
    "text": "Summary of the IPEDS Data\n\nDistinct institutions by yearDistinct institutions by year and controlDistinct institutions by year and level: Public UniversitiesDistinct institutions by year and level: Private Universities\n\n\n\n\n\nYear\nNo. Institutions\n\n\n\n\n2017\n7153\n\n\n2018\n6857\n\n\n2019\n6559\n\n\n2020\n6440\n\n\n2021\n6289\n\n\n2022\n6256\n\n\n2023\n6163\n\n\n\n\n\n\n\n\nYear\nPrivate for-profit\nPrivate not-for-profit\nPublic\n\n\n\n\n2017\n3093\n1959\n2069\n\n\n2018\n2793\n1930\n2077\n\n\n2019\n2566\n1905\n2056\n\n\n2020\n2463\n1889\n2036\n\n\n2021\n2411\n1868\n1994\n\n\n2022\n2352\n1855\n2019\n\n\n2023\n2299\n1836\n1999\n\n\n\n“Control” is defined as Public, Private Nonprofit, and Private For-Profit.\n\n\n\n\n\nYear\n2-year\n4-year\n\n\n\n\n2017\n1003\n817\n\n\n2018\n989\n840\n\n\n2019\n968\n852\n\n\n2020\n949\n852\n\n\n2021\n930\n829\n\n\n2022\n924\n859\n\n\n2023\n899\n868\n\n\n\n\n\n\n\n\nYear\n2-year\n4-year\n\n\n\n\n2017\n1034\n2371\n\n\n2018\n917\n2167\n\n\n2019\n774\n2081\n\n\n2020\n736\n2046\n\n\n2021\n709\n2016\n\n\n2022\n681\n2009\n\n\n2023\n664\n1996",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html#data-processing-and-standardization",
    "href": "appendices/app_ipeds.html#data-processing-and-standardization",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "Data Processing and Standardization",
    "text": "Data Processing and Standardization\n\nVariable Name Changes and Formatting:\n\nUNITID and year serve as the primary keys to merge datasets for analysis.\nyear was added to datasets that lacked it.\n\nHandling Missing Data and Filters:\n\nNon-relevant columns were removed.\nDatasets were filtered to retain only institutions with complete enrollment and classification data.\n\nMerging Strategy:\n\nDatasets can be joined using UNITID and year as unique identifiers.\nInstitutions missing UNITID were excluded.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html#how-to-merge-with-msi-data",
    "href": "appendices/app_ipeds.html#how-to-merge-with-msi-data",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "How to Merge with MSI Data",
    "text": "How to Merge with MSI Data\nThe IPEDS dataset can be linked with the MSI dataset using the UNITID and year variables. This allows for:\n\nIdentifying MSI institutions within IPEDS to analyze institutional characteristics.\nComparing institutional characteristics of MSI and non-MSI institutions, such as enrollment size, Carnegie classification, and financial indicators.\n\n\n\n\n\n\n\nNote\n\n\n\nAfter merging the IPEDS-MSI data with the cleaned institutional data from the citation databases, this dataset also allows for assessing research output and dataset usage by institution type, and examining trends over time in MSI status and institutional characteristics.",
    "crumbs": [
      "Appendices",
      "Cleaning IPEDS and MSI Data",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html",
    "href": "appendices/app_openalex.html",
    "title": "OpenAlex Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md"
  },
  {
    "objectID": "appendices/app_openalex.html#sec-app-openalex",
    "href": "appendices/app_openalex.html#sec-app-openalex",
    "title": "OpenAlex Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md"
  },
  {
    "objectID": "appendices/app_openalex.html#data-dictionary",
    "href": "appendices/app_openalex.html#data-dictionary",
    "title": "OpenAlex Data Dictionary",
    "section": "Data Dictionary",
    "text": "Data Dictionary\n\n\n\n\n\n\nDownload OpenAlex Source Files\n\n\n\nYou can download the source files from this link.\n\n\n\ndataset.csv\n\nDescription: Lists all datasets identified in OpenAlex. This contains details of all USDA datasets.\n\n\n\npublication_dataset_links.csv\n\nDescription: Connects publications with one or more datasets in the OpenAlex data. Indicates which publications are associated with which datasets.\n\n\n\npublication.csv\n\nDescription: This file contains information about publications, which are the central entities in this dataset.\nKey Columns:\n\nid: Unique identifier for each publication.\ntitle: Title of the publication.\ndoi: Digital Object Identifier of the publication.\nyear and month: Publication date.\nOther metadata such as citation_count, pub_type, etc.\n\n\n\n\ndataset_alias.csv\n\nDescription: Contains all the aliases (alternative names) of datasets. This helps in identifying datasets that might be referred to by different names in publications.\nKey Columns:\n\nalias_id: Unique identifier for each alias.\nparent_alias_id: Identifies the main alias for a dataset. If parent_alias_id equals alias_id, it is the primary alias.\nalias: The alias name of the dataset.\n\n\nNote: The search in OpenAlex was performed using the same aliases and flag terms applied in the Scopus data, without any optimization.\nHow to Use:\n\nTo find the main alias of a dataset, look for rows where alias_id equals parent_alias_id.\nTo find all aliases of a dataset, filter by parent_alias_id corresponding to the main alias.\n\n\n\ndyad.csv\n\nDescription: Represents the mentions of dataset aliases found within publications. Acts as a linking table between publication.csv and dataset_alias.csv.\nKey Columns:\n\nid: Unique identifier for each dyad (mention).\npublication_id: References the id in publication.csv.\nalias_id: References the alias_id in dataset_alias.csv.\nmention_candidate: The actual text mentioning the dataset in the publication.\n\n\n\n\nmodel.csv\n\nDescription: Lists the different models or methods used to identify dataset mentions within publications.\nKey Columns:\n\nid: Unique identifier for each model.\nname: Name of the model (e.g., string_matching, refmatch).\n\n\nRelevant Models:\n\nModel ID 1: string_matching\nModel ID 5: refmatch\n\nThese are the models we are focusing on to compare with data extracted from OpenAlex, as no Kaggle model has been applied there.\n\n\ndyad_model.csv\n\nDescription: Connects dyads with the models that identified them. Allows filtering dyads based on the models used.\nKey Columns:\n\ndyad_id: References the id in dyad.csv.\nmodel_id: References the id in model.csv.\n\n\nHow to Use:\n\nTo filter dyads (and thus publications) identified by specific models, perform an inner join with dyad.csv on dyad_id and filter by model_id.\n\n\n\n\n\n\n\nHow the Files are Related\n\n\n\nThe files are structured to represent entities (publications, journals, institutions, authors) and their relationships. The main publication data is in publications_main.csv, and the details about journals, institutions, and authors are in their respective files.\nThe link files (publication_journal_links.csv, publication_institution_links.csv, publication_author_links.csv) represent the many-to-many relationships between publications and these entities.\nTo find all publications by a specific author, you can use authors.csv to find the author’s author_openalex_id and then use publication_author_links.csv to find the associated publications.\nTo analyze the distribution of publications across journals, you can join publications_main.csv, publication_journal_links.csv, and journals.csv on publication_openalex_id and journal_openalex_id."
  },
  {
    "objectID": "appendices/app_openalex.html#sample-data",
    "href": "appendices/app_openalex.html#sample-data",
    "title": "OpenAlex Data Dictionary",
    "section": "Sample Data",
    "text": "Sample Data\n\npublication.csvdataset_alias.csvdyad.csvmodel.csvdyad_model.csv\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntitle\ndoi\nyear\nmonth\n\n\n\n\n321613\nNew estimates for CRNA vacancies\n\n2009\n4\n\n\n321614\nCrossing county lines: The impact of crash location and driver’s…\n10.1016/j.aap.2006…\n2006\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nalias_id\nparent_alias_id\nalias\n\n\n\n\n1676\n87\n89\nCensus of Agriculture\n\n\n1673\n12\n282\nARMS Farm Financial and Crop Production Practices\n\n\n1671\n88\n89\nUSDA Census of Agriculture\n\n\n\n\n\n\n\n\nid\npublication_id\nalias_id\nmention_candidate\n\n\n\n\n2569\n1211491\n87\ncensus of agriculture\n\n\n2573\n1199598\n88\nusda census of agriculture\n\n\n\n\n\n\n\n\nid\nname\n\n\n\n\n1\nstring_matching\n\n\n5\nrefmatch\n\n\n\n\n\n\n\n\nid\ndyad_id\nmodel_id\nscore\n\n\n\n\n4928\n2569\n1\n2.0\n\n\n4929\n2569\n4\n1.0\n\n\n4930\n2569\n2\n1.0"
  },
  {
    "objectID": "appendices/app_openalex.html#how-to-extract-publications-for-a-specific-dataset",
    "href": "appendices/app_openalex.html#how-to-extract-publications-for-a-specific-dataset",
    "title": "OpenAlex Data Dictionary",
    "section": "How to Extract Publications for a Specific Dataset",
    "text": "How to Extract Publications for a Specific Dataset\nTo find all publications associated with a particular dataset, such as the NASS Census of Agriculture, follow these steps:\n\nIdentify the Main Alias:\n\nFind the alias_id where alias_id equals parent_alias_id for the dataset.\nFor NASS Census of Agriculture, the main alias has alias_id = 89.\n\nGet All Aliases:\n\nIn dataset_alias.csv, filter rows where parent_alias_id equals 89.\nThis gives you all aliases associated with the NASS Census of Agriculture dataset.\n\nLink Aliases to Publications:\n\nIn dyad.csv, filter rows where alias_id matches any of the alias_ids obtained in step 2.\nThis will give you publication_ids of publications mentioning any alias of the dataset.\n\nRetrieve Publication Details:\n\nUsing the publication_ids from step 3, retrieve the corresponding records from publication.csv."
  },
  {
    "objectID": "appendices/app_openalex.html#filtering-publications-by-specific-models",
    "href": "appendices/app_openalex.html#filtering-publications-by-specific-models",
    "title": "OpenAlex Data Dictionary",
    "section": "Filtering Publications by Specific Models",
    "text": "Filtering Publications by Specific Models\nSince we’re interested in mentions identified by the string_matching and refmatch models (models with id 1 and 5), follow these steps:\n\nFilter Dyads by Model:\n\nIn dyad_model.csv, filter rows where model_id is 1 or 5.\nThis gives you dyad_ids linked to these models.\n\nGet Relevant Dyads:\n\nPerform an inner join with dyad.csv on dyad_id.\nThis filters dyads to only those identified by the specified models.\n\nProceed as Before:\n\nContinue with the steps in the previous section, but using the filtered dyads from step 2."
  },
  {
    "objectID": "appendices/terminology.html",
    "href": "appendices/terminology.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Terminology\nCitation databases form the foundation of modern research tracking and analysis. Digital repositories, like the test cases featured in this report, systematically catalog scholarly publications and their references to each other (De Bellis, 2009). Citation databases differ in their approaches to curating and maintaining this information. Some focus exclusively on peer-reviewed journal articles with strict inclusion criteria, while others index a broader range of research outputs including preprints, technical reports, and conference proceedings (Martín-Martín et al., 2021; Mongeon & Paul-Hus, 2016). These curation approaches affect how comprehensively each database captures research impact (Visser et al., 2021).\nUnderstanding how these databases work requires familiarity with bibliometrics - the statistical analysis of published works and their impact (Broadus, 1987). Bibliometric analysis examines patterns in publication, citation networks, and research influence (Hood & Wilson, 2001). The field emerged from early citation indices, which mapped relationships between papers through their references (Garfield, 1955).\nFor tracking USDA dataset usage, these concepts directly apply. Accurate tracking of dataset usage in scientific literature serves multiple purposes. For federal agencies like the USDA, it helps monitor the return on public data investments, find gaps in dataset use, plan future data collection, and support evidence-based policy decisions. This tracking requires reliable citation data from citation databases. Unlike standard citations, researchers often reference datasets within the text of their publications rather than citing them formally. This makes tracking dataset usage more complex.\nTo solve this tracking challenge, methods have been developed that scan publication text for dataset mentions (Lane et al., 2022). The scope and accuracy of our dataset tracking depends on what publications we can access and analyze. Because different databases curate content in different ways, it creates variation in what dataset mentions they capture and their frequency. Variations in content across sources affect our ability to accurately track dataset impact and adoption. The DemocratizingData.ai platform, for example, uses bibliometric data to monitor these dataset usage patterns, helping USDA understand how its data supports research. By comparing how different citation databases track this information, we can better understand their strengths and limitations for monitoring research impact.\n\n\n\n\n\n\n\n\n1 References\n\nBroadus, R. N. (1987). Toward a definition of “bibliometrics.” Scientometrics, 12, 373–379. https://doi.org/10.1007/bf02016680\n\n\nDe Bellis, N. (2009). Bibliometrics and citation analysis: From the science citation index to cybermetrics. Scarecrow Press. https://doi.org/10.1002/asi.21181\n\n\nGarfield, E. (1955). Citation indexes for science: A new dimension in documentation through association of ideas. Science, 122(3159), 108–111. https://doi.org/10.1126/science.122.3159.108\n\n\nHood, W. W., & Wilson, C. S. (2001). The literature of bibliometrics, scientometrics, and informetrics. Scientometrics, 52, 291–314. https://doi.org/10.1023/A:1017919924342\n\n\nLane, J., Gimeno, E., Levitskaya, E., Zhang, Z., & Zigoni, A. (2022). Data inventories for the modern age? Using data science to open government data. Harvard Data Science Review, 4(2). https://doi.org/10.1162/99608f92.8a3f2336\n\n\nMartín-Martín, A., Thelwall, M., Orduna-Malea, E., & Delgado López-Cózar, E. (2021). Google scholar, microsoft academic, scopus, dimensions, web of science, and OpenCitations’ COCI: A multidisciplinary comparison of coverage via citations. Scientometrics, 126(1), 871–906. https://doi.org/10.1007/s11192-020-03690-4\n\n\nMongeon, P., & Paul-Hus, A. (2016). The journal coverage of web of science and scopus: A comparative analysis. Scientometrics, 106, 213–228. https://doi.org/10.1007/s11192-015-1765-5\n\n\nVisser, M., Van Eck, N. J., & Waltman, L. (2021). Large-scale comparison of bibliographic data sources: Scopus, web of science, dimensions, crossref, and microsoft academic. Quantitative Science Studies, 2(1), 20–41. https://doi.org/10.1162/qss_a_00112",
    "crumbs": [
      "Appendices",
      "Terminology"
    ]
  },
  {
    "objectID": "appendices/workflow/step01/define_data_assets.html",
    "href": "appendices/workflow/step01/define_data_assets.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to compile a structured list of dataset names and their commonly used variations.\n\n\n\n\n\n\n\nNote\n\n\n\nThe data assets featured here consist of those collected by the USDA, primarily from the Economic Research Service (ERS) and the National Agricultural Statistics Service (NASS). These data assets are widely used in agricultural economics and food systems research.\n\n\n\n\nIn late July 2023, an initial set of 21 reports were received containing a report name and a URL link to database curated by Cornell University. These reports are part of the USDA’s efforts to track data usage across various research applications. However, the names of these reports were highly generic, making it difficult to precisely identify them in citation databases. Examples include reports titled “Agricultural Prices” and “Farm Labor,” which lack specificity when compared to more structured dataset identifiers.\nData Processing and Standardization\nTo improve identification and searchability, the input was analyzed and transformed into a structured list that included:\n\nInternational Standard Serial Numbers (ISSNs): Each of the 21 reports was assigned an ISSN, where available, to provide a standardized identifier.\nAlias Creation: Generic report names were appended with the term report to better distinguish them from other similarly named publications in research literature.\nExpanded Search Terms: Additional variations of dataset names were included to account for different citation styles and possible ways authors reference these reports.\n\nThe final dataset classification involved:\n\nMain Data Asset (Parent Record): The original 21 reports, each representing a distinct dataset.\nAliases: ISSNs and URLs served as aliases to improve retrieval accuracy.\nSearch Term Expansion: Combining report names with different citation formats led to a total of 64 search terms (21 parent records + 43 aliases).\n\nThis standardization process improved the efficiency of identifying NASS datasets across publications indexed by citation databases such as Scopus, OpenAlex, and Dimensions.\n\n\n\nThe process of identifying ERS data assets occurred in two phases: (1) an initial dataset compilation, and (2) a refinement process incorporating feedback from a team of agricultural economists at Colorado State University (CSU). This process was meant to yield a list of data assets was both comprehensive and relevant to the research community tracking USDA dataset usage.\nPhase 1: Initial Compilation of ERS Data Assets\nIn October 2023, an initial list of 2,103 ERS records was compiled. These records included dataset names and, in some cases, associated aliases. The list was then reviewed by Professor Julia Lane, who identified and removed 144 records that were not suitable for machine learning-based dataset tracking.\nReasons for Exclusion\n\nRecords were too generic – Terms such as “Milk, Cotton, and CSV Format of National Data” were too broad to be meaningfully identified in citation databases.\nRecords were too specific – Entries such as “Table 15—Agricultural Chemical Input” and “Southeast: 1982-91, 1992-97” were references within broader reports rather than standalone data assets.\n\nAfter these exclusions, the remaining 1,959 records represented the initial list of ERS data assets.\nPhase 2: Refinement with CSU Team\nA team of agricultural economists at CSU were consulted to refine the list so that it accurately captured key USDA datasets that may have been overlooked in the initial process. This involved:\n\nReviewing dataset usage in prior USDA research – Identifying which datasets were frequently cited.\nCross-checking with known data users – Ensuring that key datasets used by agricultural economists were included.\nExpanding alias definitions – Recognizing dataset acronyms and alternative naming conventions.\n\nAs part of this process, an additional set of assets was incorporated, including datasets that had been previously identified in the Year 1 USDA project. Notably, datasets such as the Census of Agriculture and the Agricultural Resource Management Survey (ARMS) were added, along with key acronyms like FoodAPS. This phase contributed:\n\n12 new parent records\n8 additional alias records\nTotal: 20 new search terms\n\nFinal Data Asset Identification\nUnlike NASS data assets, which had ISSNs and DOIs, ERS datasets were primarily linked through URLs. The final structured dataset included:\n\n1,959 parent records (main ERS datasets)\n1,959 alias records (URLs serving as dataset identifiers)\n20 additional records from the CSU consultation\nTotal: 3,918 search terms\n\nThrough this two-phase process, the list of ERS data assets evolved from an initial broad set of records into a refined, structured collection of datasets that could be effectively tracked across citation databases.\n\n\n\nThe data assets represent those most frequently used in agricultural economics research, spanning topics from farm management to food security. The final set of data assets, their producing agencies, and descriptions are presented in Table 1.\n\n\n\nTable 1: List of USDA Data Assets\n\n\n\n\n\nDataset Name\nProduced By\nDescription\n\n\n\n\nCensus of Agriculture\nNASS\nConducted every five years, it provides comprehensive data on U.S. farms, ranches, and producers.\n\n\nAgricultural Resource Management Survey (ARMS)\nERS\nA USDA survey on farm financials, production practices, and resource use.\n\n\nFood Acquisition and Purchase Survey (FoodAPS)\nERS\nA nationally representative survey tracking U.S. household food purchases and acquisitions.\n\n\nCurrent Population Survey Food Security Supplement (CPS-FSS)\nERS\nAn annual supplement to the Current Population Survey (CPS) measuring U.S. household food security.\n\n\nFood Access Research Atlas (FARA)\nERS\nA USDA tool mapping food access based on store locations and socioeconomic data.\n\n\nRural-Urban Continuum Code (RUCC)\nERS\nA classification system distinguishing U.S. counties by rural and urban characteristics.\n\n\nHousehold Food Security Survey Module\nERS\nA USDA survey module used to assess food insecurity levels in households.\n\n\nLocal Food Marketing Practices Survey\nNASS\nA USDA survey on U.S. farms’ local food sales, direct-to-consumer marketing, and supply chains.\n\n\nFarm to School Census\nFNS\nA USDA survey tracking school food procurement and local farm partnerships.\n\n\nQuarterly Food at Home Price Database (QFAHPD)\nERS\nA database of U.S. retail food prices by product, region, and time.\n\n\nTenure Ownership and Transition of Agricultural Land (TOTAL)\nNASS\nA survey collecting data on farmland ownership, leasing, and transfer.\n\n\nTransition of Agricultural Land Survey\nNASS\nA component of TOTAL that examines farmland ownership changes and succession plans.\n\n\nInformation Resources, Inc. (IRI) InfoScan\nCircana (formerly IRI)\nA commercial scanner dataset tracking retail food and consumer goods purchases.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo provide a comprehensive reference for dataset tracking, this Appendix includes a detailed list of data assets and their corresponding aliases, collectively referred to as dyads. Each dyad represents a dataset-name and alias pair used in citation database searches, allowing for more precise identification of dataset mentions in research publications. These aliases include acronyms, alternate spellings, dataset variations, and associated URLs, ensuring broad coverage across different citation practices. The dyad list serves as the foundation for dataset extraction and disambiguation across Scopus, OpenAlex, and Dimensions.",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Define Data Assets"
    ]
  },
  {
    "objectID": "appendices/workflow/step01/define_data_assets.html#sec-data",
    "href": "appendices/workflow/step01/define_data_assets.html#sec-data",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to compile a structured list of dataset names and their commonly used variations.\n\n\n\n\n\n\n\nNote\n\n\n\nThe data assets featured here consist of those collected by the USDA, primarily from the Economic Research Service (ERS) and the National Agricultural Statistics Service (NASS). These data assets are widely used in agricultural economics and food systems research.\n\n\n\n\nIn late July 2023, an initial set of 21 reports were received containing a report name and a URL link to database curated by Cornell University. These reports are part of the USDA’s efforts to track data usage across various research applications. However, the names of these reports were highly generic, making it difficult to precisely identify them in citation databases. Examples include reports titled “Agricultural Prices” and “Farm Labor,” which lack specificity when compared to more structured dataset identifiers.\nData Processing and Standardization\nTo improve identification and searchability, the input was analyzed and transformed into a structured list that included:\n\nInternational Standard Serial Numbers (ISSNs): Each of the 21 reports was assigned an ISSN, where available, to provide a standardized identifier.\nAlias Creation: Generic report names were appended with the term report to better distinguish them from other similarly named publications in research literature.\nExpanded Search Terms: Additional variations of dataset names were included to account for different citation styles and possible ways authors reference these reports.\n\nThe final dataset classification involved:\n\nMain Data Asset (Parent Record): The original 21 reports, each representing a distinct dataset.\nAliases: ISSNs and URLs served as aliases to improve retrieval accuracy.\nSearch Term Expansion: Combining report names with different citation formats led to a total of 64 search terms (21 parent records + 43 aliases).\n\nThis standardization process improved the efficiency of identifying NASS datasets across publications indexed by citation databases such as Scopus, OpenAlex, and Dimensions.\n\n\n\nThe process of identifying ERS data assets occurred in two phases: (1) an initial dataset compilation, and (2) a refinement process incorporating feedback from a team of agricultural economists at Colorado State University (CSU). This process was meant to yield a list of data assets was both comprehensive and relevant to the research community tracking USDA dataset usage.\nPhase 1: Initial Compilation of ERS Data Assets\nIn October 2023, an initial list of 2,103 ERS records was compiled. These records included dataset names and, in some cases, associated aliases. The list was then reviewed by Professor Julia Lane, who identified and removed 144 records that were not suitable for machine learning-based dataset tracking.\nReasons for Exclusion\n\nRecords were too generic – Terms such as “Milk, Cotton, and CSV Format of National Data” were too broad to be meaningfully identified in citation databases.\nRecords were too specific – Entries such as “Table 15—Agricultural Chemical Input” and “Southeast: 1982-91, 1992-97” were references within broader reports rather than standalone data assets.\n\nAfter these exclusions, the remaining 1,959 records represented the initial list of ERS data assets.\nPhase 2: Refinement with CSU Team\nA team of agricultural economists at CSU were consulted to refine the list so that it accurately captured key USDA datasets that may have been overlooked in the initial process. This involved:\n\nReviewing dataset usage in prior USDA research – Identifying which datasets were frequently cited.\nCross-checking with known data users – Ensuring that key datasets used by agricultural economists were included.\nExpanding alias definitions – Recognizing dataset acronyms and alternative naming conventions.\n\nAs part of this process, an additional set of assets was incorporated, including datasets that had been previously identified in the Year 1 USDA project. Notably, datasets such as the Census of Agriculture and the Agricultural Resource Management Survey (ARMS) were added, along with key acronyms like FoodAPS. This phase contributed:\n\n12 new parent records\n8 additional alias records\nTotal: 20 new search terms\n\nFinal Data Asset Identification\nUnlike NASS data assets, which had ISSNs and DOIs, ERS datasets were primarily linked through URLs. The final structured dataset included:\n\n1,959 parent records (main ERS datasets)\n1,959 alias records (URLs serving as dataset identifiers)\n20 additional records from the CSU consultation\nTotal: 3,918 search terms\n\nThrough this two-phase process, the list of ERS data assets evolved from an initial broad set of records into a refined, structured collection of datasets that could be effectively tracked across citation databases.\n\n\n\nThe data assets represent those most frequently used in agricultural economics research, spanning topics from farm management to food security. The final set of data assets, their producing agencies, and descriptions are presented in Table 1.\n\n\n\nTable 1: List of USDA Data Assets\n\n\n\n\n\nDataset Name\nProduced By\nDescription\n\n\n\n\nCensus of Agriculture\nNASS\nConducted every five years, it provides comprehensive data on U.S. farms, ranches, and producers.\n\n\nAgricultural Resource Management Survey (ARMS)\nERS\nA USDA survey on farm financials, production practices, and resource use.\n\n\nFood Acquisition and Purchase Survey (FoodAPS)\nERS\nA nationally representative survey tracking U.S. household food purchases and acquisitions.\n\n\nCurrent Population Survey Food Security Supplement (CPS-FSS)\nERS\nAn annual supplement to the Current Population Survey (CPS) measuring U.S. household food security.\n\n\nFood Access Research Atlas (FARA)\nERS\nA USDA tool mapping food access based on store locations and socioeconomic data.\n\n\nRural-Urban Continuum Code (RUCC)\nERS\nA classification system distinguishing U.S. counties by rural and urban characteristics.\n\n\nHousehold Food Security Survey Module\nERS\nA USDA survey module used to assess food insecurity levels in households.\n\n\nLocal Food Marketing Practices Survey\nNASS\nA USDA survey on U.S. farms’ local food sales, direct-to-consumer marketing, and supply chains.\n\n\nFarm to School Census\nFNS\nA USDA survey tracking school food procurement and local farm partnerships.\n\n\nQuarterly Food at Home Price Database (QFAHPD)\nERS\nA database of U.S. retail food prices by product, region, and time.\n\n\nTenure Ownership and Transition of Agricultural Land (TOTAL)\nNASS\nA survey collecting data on farmland ownership, leasing, and transfer.\n\n\nTransition of Agricultural Land Survey\nNASS\nA component of TOTAL that examines farmland ownership changes and succession plans.\n\n\nInformation Resources, Inc. (IRI) InfoScan\nCircana (formerly IRI)\nA commercial scanner dataset tracking retail food and consumer goods purchases.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo provide a comprehensive reference for dataset tracking, this Appendix includes a detailed list of data assets and their corresponding aliases, collectively referred to as dyads. Each dyad represents a dataset-name and alias pair used in citation database searches, allowing for more precise identification of dataset mentions in research publications. These aliases include acronyms, alternate spellings, dataset variations, and associated URLs, ensuring broad coverage across different citation practices. The dyad list serves as the foundation for dataset extraction and disambiguation across Scopus, OpenAlex, and Dimensions.",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Define Data Assets"
    ]
  },
  {
    "objectID": "appendices/workflow/step02_01/03openalex.html",
    "href": "appendices/workflow/step02_01/03openalex.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The second citation database used is OpenAlex, an open catalog of scholarly publications that provides public acess to metadata and, when available, full-text content for open-access publications via its API. Unlike Scopus, which provides controls access to licensed content, OpenAlex indexes only open-access publications or those for which open metadata has been made available by publishers.\nTwo methods were used to identify USDA dataset mentions in OpenAlex: a full-text search (described below) and a seed corpus approach (described in the following section). Both methods focused on peer-reviewed journal articles published between 2017 and 2023 and restricted the dataset to final published versions, excluding preprints and earlier drafts to avoid duplication across versions.\nThe full-text search relied on querying OpenAlex’s full-text search index using combinations of dataset aliases (e.g., alternate names, acronyms) and institutional flag terms (e.g., “USDA,” “NASS”). The combination of dataset alias and flag terms ensured that retrieved publications made an explicit connection to the correct data source. A “true” dataset mention was recorded only when at least one alias and one flag term appeared in the same publication, increasing the precision of captured dataset mentions.1\nQueries were implemented using the pyalex Python package2, which manages API requests and enforces OpenAlex’s usage rate limits. The search used the search and filter endpoints, targeting English-language, open-access articles or reviews published after 2017. Results were returned in JSON format based on the OpenAlex Work object schema, including fields for publication metadata, authorship, journal, concepts, citations, and open access status. Each record included metadata fields such as:\n\ndisplay_name (publication title)\nauthorships (authors and affiliations)\nhost_venue.display_name (journal)\ndoi (digital object identifier)\nconcepts (topics)\ncited_by_count (citation counts)\ntype (publication type, e.g., “article”)\npublication_year (year article was publish)\nlanguage (language, English only)\nis_oa (open access)\n\nThe code used to implement this querying and filtering process is publicly available here.\n\n\nAlthough the OpenAlex API provides access to full-text search, limitations in content ingestion affect result completeness. OpenAlex receives publication text through two primary ingestion methods: PDF extraction and n-grams delivery.\nIn the PDF ingestion method, OpenAlex extracts text directly from the article PDF. However, the references section is not included in the searchable text. References are processed separately to create citation pointers between scholarly works, meaning that mentions of datasets appearing only in bibliographies are not discoverable through full-text search.\nIn the n-grams ingestion method, OpenAlex does not receive the full article text. Instead, it receives a set of extracted word sequences (n-grams) from the publisher or author. These n-grams represent fragments of text—typically short sequences of one, two, or three words—which are not guaranteed to preserve full continuous phrases. As a result, complete dataset names may be broken apart or omitted, reducing the likelihood that search queries match the intended aliases.\nThese ingestion and indexing limitations affect the completeness of results when relying solely on OpenAlex full-text search. Mentions of USDA datasets that appear either exclusively in references or are fragmented within n-grams may be missed. To address these limitations, an alternative search method was developed based on constructing a filtered seed corpus of publications for local full-text analysis.\nRefer to this Appendix for additional details on file construction."
  },
  {
    "objectID": "appendices/workflow/step02_01/03openalex.html#openalex",
    "href": "appendices/workflow/step02_01/03openalex.html#openalex",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The second citation database used is OpenAlex, an open catalog of scholarly publications that provides public acess to metadata and, when available, full-text content for open-access publications via its API. Unlike Scopus, which provides controls access to licensed content, OpenAlex indexes only open-access publications or those for which open metadata has been made available by publishers.\nTwo methods were used to identify USDA dataset mentions in OpenAlex: a full-text search (described below) and a seed corpus approach (described in the following section). Both methods focused on peer-reviewed journal articles published between 2017 and 2023 and restricted the dataset to final published versions, excluding preprints and earlier drafts to avoid duplication across versions.\nThe full-text search relied on querying OpenAlex’s full-text search index using combinations of dataset aliases (e.g., alternate names, acronyms) and institutional flag terms (e.g., “USDA,” “NASS”). The combination of dataset alias and flag terms ensured that retrieved publications made an explicit connection to the correct data source. A “true” dataset mention was recorded only when at least one alias and one flag term appeared in the same publication, increasing the precision of captured dataset mentions.1\nQueries were implemented using the pyalex Python package2, which manages API requests and enforces OpenAlex’s usage rate limits. The search used the search and filter endpoints, targeting English-language, open-access articles or reviews published after 2017. Results were returned in JSON format based on the OpenAlex Work object schema, including fields for publication metadata, authorship, journal, concepts, citations, and open access status. Each record included metadata fields such as:\n\ndisplay_name (publication title)\nauthorships (authors and affiliations)\nhost_venue.display_name (journal)\ndoi (digital object identifier)\nconcepts (topics)\ncited_by_count (citation counts)\ntype (publication type, e.g., “article”)\npublication_year (year article was publish)\nlanguage (language, English only)\nis_oa (open access)\n\nThe code used to implement this querying and filtering process is publicly available here.\n\n\nAlthough the OpenAlex API provides access to full-text search, limitations in content ingestion affect result completeness. OpenAlex receives publication text through two primary ingestion methods: PDF extraction and n-grams delivery.\nIn the PDF ingestion method, OpenAlex extracts text directly from the article PDF. However, the references section is not included in the searchable text. References are processed separately to create citation pointers between scholarly works, meaning that mentions of datasets appearing only in bibliographies are not discoverable through full-text search.\nIn the n-grams ingestion method, OpenAlex does not receive the full article text. Instead, it receives a set of extracted word sequences (n-grams) from the publisher or author. These n-grams represent fragments of text—typically short sequences of one, two, or three words—which are not guaranteed to preserve full continuous phrases. As a result, complete dataset names may be broken apart or omitted, reducing the likelihood that search queries match the intended aliases.\nThese ingestion and indexing limitations affect the completeness of results when relying solely on OpenAlex full-text search. Mentions of USDA datasets that appear either exclusively in references or are fragmented within n-grams may be missed. To address these limitations, an alternative search method was developed based on constructing a filtered seed corpus of publications for local full-text analysis.\nRefer to this Appendix for additional details on file construction."
  },
  {
    "objectID": "appendices/workflow/step02_01/03openalex.html#footnotes",
    "href": "appendices/workflow/step02_01/03openalex.html#footnotes",
    "title": "Citation Database Assessment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis procedure increased the likelihood of capturing genuine dataset references rather than incidental matches to individual words. Initial drafts of the query incorrectly included terms like “NASS” and “USDA” in the alias list. This was corrected to ensure that aliases strictly referred to dataset names, and flag terms referred to organizations.↩︎\nPyalex is an open-source library designed to facilitate interaction with the OpenAlex API; see https://help.openalex.org/hc/en-us/articles/27086501974551-Projects-Using-OpenAlex for more information. The package manages request formatting and automates compliance with OpenAlex’s “polite pool” rate limits, which restrict the number of requests per minute and impose backoff delays. Pyalex introduced automatic pauses between requests, with a default retry_backoff_factor of 100 milliseconds, to ensure stable and continuous retrieval. This setup enabled systematic querying while adhering to OpenAlex’s usage policies.↩︎"
  },
  {
    "objectID": "appendices/workflow/step02_01/extract_dataset_mentions.html",
    "href": "appendices/workflow/step02_01/extract_dataset_mentions.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to build a dataset of publications that reference the dataset name aliases for the USDA data assets across Scopus, OpenAlex, and Dimensions.\n\nTo generate this dataset, the process requires:\n\nDataset name aliases (from Step 1)\nSearch routines tailored to each citation database to extract relevant publications\n\nSearch routines, described below, guide this step, as dataset mentions are often inconsistent across publications—appearing in titles, abstracts, full text, or reference lists. Scopus uses a structured seed corpus to refine searches; OpenAlex uses both a full text search and defines a seed corpus; Dimensions relies only on direct queries across their full publication records. The outputs of this step are three publication-level datasets, one for each citation database, which are further analyzed in subsequent steps.\n\nScopusOpenAlexDimensions\n\n\n\n\nThe search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.\n\n\n\n\n\n\n\nThe second citation database used is OpenAlex, an open catalog of scholarly publications that provides public acess to metadata and, when available, full-text content for open-access publications via its API. Unlike Scopus, which provides controls access to licensed content, OpenAlex indexes only open-access publications or those for which open metadata has been made available by publishers.\nTwo methods were used to identify USDA dataset mentions in OpenAlex: a full-text search (described below) and a seed corpus approach (described in the following section). Both methods focused on peer-reviewed journal articles published between 2017 and 2023 and restricted the dataset to final published versions, excluding preprints and earlier drafts to avoid duplication across versions.\nThe full-text search relied on querying OpenAlex’s full-text search index using combinations of dataset aliases (e.g., alternate names, acronyms) and institutional flag terms (e.g., “USDA,” “NASS”). The combination of dataset alias and flag terms ensured that retrieved publications made an explicit connection to the correct data source. A “true” dataset mention was recorded only when at least one alias and one flag term appeared in the same publication, increasing the precision of captured dataset mentions.3\nQueries were implemented using the pyalex Python package4, which manages API requests and enforces OpenAlex’s usage rate limits. The search used the search and filter endpoints, targeting English-language, open-access articles or reviews published after 2017. Results were returned in JSON format based on the OpenAlex Work object schema, including fields for publication metadata, authorship, journal, concepts, citations, and open access status. Each record included metadata fields such as:\n\ndisplay_name (publication title)\nauthorships (authors and affiliations)\nhost_venue.display_name (journal)\ndoi (digital object identifier)\nconcepts (topics)\ncited_by_count (citation counts)\ntype (publication type, e.g., “article”)\npublication_year (year article was publish)\nlanguage (language, English only)\nis_oa (open access)\n\nThe code used to implement this querying and filtering process is publicly available here.\n\n\nAlthough the OpenAlex API provides access to full-text search, limitations in content ingestion affect result completeness. OpenAlex receives publication text through two primary ingestion methods: PDF extraction and n-grams delivery.\nIn the PDF ingestion method, OpenAlex extracts text directly from the article PDF. However, the references section is not included in the searchable text. References are processed separately to create citation pointers between scholarly works, meaning that mentions of datasets appearing only in bibliographies are not discoverable through full-text search.\nIn the n-grams ingestion method, OpenAlex does not receive the full article text. Instead, it receives a set of extracted word sequences (n-grams) from the publisher or author. These n-grams represent fragments of text—typically short sequences of one, two, or three words—which are not guaranteed to preserve full continuous phrases. As a result, complete dataset names may be broken apart or omitted, reducing the likelihood that search queries match the intended aliases.\nThese ingestion and indexing limitations affect the completeness of results when relying solely on OpenAlex full-text search. Mentions of USDA datasets that appear either exclusively in references or are fragmented within n-grams may be missed. To address these limitations, an alternative search method was developed based on constructing a filtered seed corpus of publications for local full-text analysis.\nRefer to this Appendix for additional details on file construction.\n\n\n\n\n\n\nTo identify publications mentioning USDA datasets, we used the Dimensions.ai API, following the same general methodology applied in Scopus and OpenAlex. We reused the same dataset aliases, institutional flag terms, and overall search criteria to ensure consistency across sources. The search covered scholarly publications from 2017 to 2023 and was restricted to works authored by at least one researcher affiliated with a U.S.-based institution.\nDimensions queries are written using a structured Domain Specific Language (DSL). We constructed boolean queries that combined multiple dataset aliases (e.g., “NASS Census of Agriculture”, “USDA Census”, “Agricultural Census”) with institutional identifiers (e.g., “USDA”, “NASS”, “U.S. Department of Agriculture”). As with Scopus and OpenAlex, both a dataset alias and an institutional flag term were required to appear in each result. These terms were grouped using OR within each category and then combined with an AND across categories. For example:\n\n(“NASS Census of Agriculture” OR “Census of Agriculture” OR “USDA Census of Agriculture” OR “Agricultural Census” OR “USDA Census” OR “AG Census”) AND (USDA OR “US Department of Agriculture” OR “United States Department of Agriculture” OR NASS OR “National Agricultural Statistics Service”)\n\nWe implemented this process using the dimcli Python library, which provides a streamlined interface to the Dimensions.ai API and automates result pagination. A significant advantage of this approach is the capability of the Dimensions.ai platform to manage complex searches directly, resulting in precise results and reduced computational overhead. By executing these queries directly through the API, we avoided the technical complexity associated with downloading and locally processing large amounts of textual content. Moreover, the Dimensions.ai API results can be automatically structured into an analysis-ready DataFrame format. This simplified data structure greatly facilitated our subsequent validation, data integration, and analytical workflows.\nTo maintain methodological consistency with Scopus and OpenAlex, the following filters were applied to the search:\n\nEnglish-language publications\nWorks published between 2017-2023\nDocument types: articles, chapters, proceedings, monographs, and preprints\nAuthor affiliations: Publications were filtered to include only those authored by researchers affiliated with at least one U.S.-based institution.\n\nFor comparability with the Scopus and OpenAlex samples, only publications classified as “articles” were retained for final analysis. This restriction reduces duplication across versions (e.g., preprints, proceedings) and reflects our focus on peer-reviewed scholarly output.\nFor each article, we retrieved metadata including title, authors, DOI, journal, abstract, publication date, citation counts, subject classifications, and links. These fields supported topic-level analysis, author and institution mapping, and validation of dataset mentions.\nUsing Dimensions.ai provided two main technical advantages. First, because the platform supports full-text query execution natively, we avoided the need to download or parse external files. Second, the API responses were easily converted into analysis-ready DataFrames, which simplified downstream validation and integration with other sources.",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Extract Dataset Mentions"
    ]
  },
  {
    "objectID": "appendices/workflow/step02_01/extract_dataset_mentions.html#sec-data-idn",
    "href": "appendices/workflow/step02_01/extract_dataset_mentions.html#sec-data-idn",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to build a dataset of publications that reference the dataset name aliases for the USDA data assets across Scopus, OpenAlex, and Dimensions.\n\nTo generate this dataset, the process requires:\n\nDataset name aliases (from Step 1)\nSearch routines tailored to each citation database to extract relevant publications\n\nSearch routines, described below, guide this step, as dataset mentions are often inconsistent across publications—appearing in titles, abstracts, full text, or reference lists. Scopus uses a structured seed corpus to refine searches; OpenAlex uses both a full text search and defines a seed corpus; Dimensions relies only on direct queries across their full publication records. The outputs of this step are three publication-level datasets, one for each citation database, which are further analyzed in subsequent steps.\n\nScopusOpenAlexDimensions\n\n\n\n\nThe search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.\n\n\n\n\n\n\n\nThe second citation database used is OpenAlex, an open catalog of scholarly publications that provides public acess to metadata and, when available, full-text content for open-access publications via its API. Unlike Scopus, which provides controls access to licensed content, OpenAlex indexes only open-access publications or those for which open metadata has been made available by publishers.\nTwo methods were used to identify USDA dataset mentions in OpenAlex: a full-text search (described below) and a seed corpus approach (described in the following section). Both methods focused on peer-reviewed journal articles published between 2017 and 2023 and restricted the dataset to final published versions, excluding preprints and earlier drafts to avoid duplication across versions.\nThe full-text search relied on querying OpenAlex’s full-text search index using combinations of dataset aliases (e.g., alternate names, acronyms) and institutional flag terms (e.g., “USDA,” “NASS”). The combination of dataset alias and flag terms ensured that retrieved publications made an explicit connection to the correct data source. A “true” dataset mention was recorded only when at least one alias and one flag term appeared in the same publication, increasing the precision of captured dataset mentions.3\nQueries were implemented using the pyalex Python package4, which manages API requests and enforces OpenAlex’s usage rate limits. The search used the search and filter endpoints, targeting English-language, open-access articles or reviews published after 2017. Results were returned in JSON format based on the OpenAlex Work object schema, including fields for publication metadata, authorship, journal, concepts, citations, and open access status. Each record included metadata fields such as:\n\ndisplay_name (publication title)\nauthorships (authors and affiliations)\nhost_venue.display_name (journal)\ndoi (digital object identifier)\nconcepts (topics)\ncited_by_count (citation counts)\ntype (publication type, e.g., “article”)\npublication_year (year article was publish)\nlanguage (language, English only)\nis_oa (open access)\n\nThe code used to implement this querying and filtering process is publicly available here.\n\n\nAlthough the OpenAlex API provides access to full-text search, limitations in content ingestion affect result completeness. OpenAlex receives publication text through two primary ingestion methods: PDF extraction and n-grams delivery.\nIn the PDF ingestion method, OpenAlex extracts text directly from the article PDF. However, the references section is not included in the searchable text. References are processed separately to create citation pointers between scholarly works, meaning that mentions of datasets appearing only in bibliographies are not discoverable through full-text search.\nIn the n-grams ingestion method, OpenAlex does not receive the full article text. Instead, it receives a set of extracted word sequences (n-grams) from the publisher or author. These n-grams represent fragments of text—typically short sequences of one, two, or three words—which are not guaranteed to preserve full continuous phrases. As a result, complete dataset names may be broken apart or omitted, reducing the likelihood that search queries match the intended aliases.\nThese ingestion and indexing limitations affect the completeness of results when relying solely on OpenAlex full-text search. Mentions of USDA datasets that appear either exclusively in references or are fragmented within n-grams may be missed. To address these limitations, an alternative search method was developed based on constructing a filtered seed corpus of publications for local full-text analysis.\nRefer to this Appendix for additional details on file construction.\n\n\n\n\n\n\nTo identify publications mentioning USDA datasets, we used the Dimensions.ai API, following the same general methodology applied in Scopus and OpenAlex. We reused the same dataset aliases, institutional flag terms, and overall search criteria to ensure consistency across sources. The search covered scholarly publications from 2017 to 2023 and was restricted to works authored by at least one researcher affiliated with a U.S.-based institution.\nDimensions queries are written using a structured Domain Specific Language (DSL). We constructed boolean queries that combined multiple dataset aliases (e.g., “NASS Census of Agriculture”, “USDA Census”, “Agricultural Census”) with institutional identifiers (e.g., “USDA”, “NASS”, “U.S. Department of Agriculture”). As with Scopus and OpenAlex, both a dataset alias and an institutional flag term were required to appear in each result. These terms were grouped using OR within each category and then combined with an AND across categories. For example:\n\n(“NASS Census of Agriculture” OR “Census of Agriculture” OR “USDA Census of Agriculture” OR “Agricultural Census” OR “USDA Census” OR “AG Census”) AND (USDA OR “US Department of Agriculture” OR “United States Department of Agriculture” OR NASS OR “National Agricultural Statistics Service”)\n\nWe implemented this process using the dimcli Python library, which provides a streamlined interface to the Dimensions.ai API and automates result pagination. A significant advantage of this approach is the capability of the Dimensions.ai platform to manage complex searches directly, resulting in precise results and reduced computational overhead. By executing these queries directly through the API, we avoided the technical complexity associated with downloading and locally processing large amounts of textual content. Moreover, the Dimensions.ai API results can be automatically structured into an analysis-ready DataFrame format. This simplified data structure greatly facilitated our subsequent validation, data integration, and analytical workflows.\nTo maintain methodological consistency with Scopus and OpenAlex, the following filters were applied to the search:\n\nEnglish-language publications\nWorks published between 2017-2023\nDocument types: articles, chapters, proceedings, monographs, and preprints\nAuthor affiliations: Publications were filtered to include only those authored by researchers affiliated with at least one U.S.-based institution.\n\nFor comparability with the Scopus and OpenAlex samples, only publications classified as “articles” were retained for final analysis. This restriction reduces duplication across versions (e.g., preprints, proceedings) and reflects our focus on peer-reviewed scholarly output.\nFor each article, we retrieved metadata including title, authors, DOI, journal, abstract, publication date, citation counts, subject classifications, and links. These fields supported topic-level analysis, author and institution mapping, and validation of dataset mentions.\nUsing Dimensions.ai provided two main technical advantages. First, because the platform supports full-text query execution natively, we avoided the need to download or parse external files. Second, the API responses were easily converted into analysis-ready DataFrames, which simplified downstream validation and integration with other sources.",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Extract Dataset Mentions"
    ]
  },
  {
    "objectID": "appendices/workflow/step02_01/extract_dataset_mentions.html#footnotes",
    "href": "appendices/workflow/step02_01/extract_dataset_mentions.html#footnotes",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExplanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.↩︎\nExplanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.↩︎\nThis procedure increased the likelihood of capturing genuine dataset references rather than incidental matches to individual words. Initial drafts of the query incorrectly included terms like “NASS” and “USDA” in the alias list. This was corrected to ensure that aliases strictly referred to dataset names, and flag terms referred to organizations.↩︎\nPyalex is an open-source library designed to facilitate interaction with the OpenAlex API; see https://help.openalex.org/hc/en-us/articles/27086501974551-Projects-Using-OpenAlex for more information. The package manages request formatting and automates compliance with OpenAlex’s “polite pool” rate limits, which restrict the number of requests per minute and impose backoff delays. Pyalex introduced automatic pauses between requests, with a default retry_backoff_factor of 100 milliseconds, to ensure stable and continuous retrieval. This setup enabled systematic querying while adhering to OpenAlex’s usage policies.↩︎",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Extract Dataset Mentions"
    ]
  },
  {
    "objectID": "appendices/workflow/step02_02/02openalex.html",
    "href": "appendices/workflow/step02_02/02openalex.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "Given the limitations of OpenAlex full text search, a Seed Corpus and Search Corpus were used to facilitate more accurate identification of USDA dataset mentions in scholarly publications within the OpenAlex citation database.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025)."
  },
  {
    "objectID": "appendices/workflow/step02_02/02openalex.html#openalex",
    "href": "appendices/workflow/step02_02/02openalex.html#openalex",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "Given the limitations of OpenAlex full text search, a Seed Corpus and Search Corpus were used to facilitate more accurate identification of USDA dataset mentions in scholarly publications within the OpenAlex citation database.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025)."
  },
  {
    "objectID": "appendices/workflow/step02_02/create_seed_corpus.html",
    "href": "appendices/workflow/step02_02/create_seed_corpus.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "For Scopus and OpenAlex, a structured seed corpus was used to establish a more targeted search space. This seed corpus approach was necessary to balance recall (capturing relevant mentions) and precision (minimizing false positives). The process involved:\n\nRestricted search strategies using reference lists and available full-text searches\nMachine learning-assisted review to refine dataset mentions\nManual refinements to resolve ambiguities, consolidate duplicate aliases, and incorporate missing terms.\n\nThis structured search space helped mitigate the constraints of Scopus’s API and address the limitations of the OpenAlex full-text search to ensure that dataset mentions were captured as comprehensively as possible.\n\nScopusOpenAlexDimensions\n\n\n\n\nThere are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.\n\n\n\n\n\nGiven the limitations of OpenAlex full text search, a Seed Corpus and Search Corpus were used to facilitate more accurate identification of USDA dataset mentions in scholarly publications within the OpenAlex citation database.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025).\n\n\n\nThe seed corpus approach was only applied to Scopus and OpenAlex.",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Creating a Seed Corpus"
    ]
  },
  {
    "objectID": "appendices/workflow/step02_02/create_seed_corpus.html#sec-seed-corpus",
    "href": "appendices/workflow/step02_02/create_seed_corpus.html#sec-seed-corpus",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "For Scopus and OpenAlex, a structured seed corpus was used to establish a more targeted search space. This seed corpus approach was necessary to balance recall (capturing relevant mentions) and precision (minimizing false positives). The process involved:\n\nRestricted search strategies using reference lists and available full-text searches\nMachine learning-assisted review to refine dataset mentions\nManual refinements to resolve ambiguities, consolidate duplicate aliases, and incorporate missing terms.\n\nThis structured search space helped mitigate the constraints of Scopus’s API and address the limitations of the OpenAlex full-text search to ensure that dataset mentions were captured as comprehensively as possible.\n\nScopusOpenAlexDimensions\n\n\n\n\nThere are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.\n\n\n\n\n\nGiven the limitations of OpenAlex full text search, a Seed Corpus and Search Corpus were used to facilitate more accurate identification of USDA dataset mentions in scholarly publications within the OpenAlex citation database.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025).\n\n\n\nThe seed corpus approach was only applied to Scopus and OpenAlex.",
    "crumbs": [
      "Appendices",
      "Workflow",
      "Creating a Seed Corpus"
    ]
  },
  {
    "objectID": "appendices/workflow/step03/clean_pub_data.html",
    "href": "appendices/workflow/step03/clean_pub_data.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to standardize and resolve inconsistencies in publication records by disambiguating journal names, author affiliations, and institutions across the three databases.\n\nTo compare publication coverage across citation databases, we first identify all journals that contain publications using each dataset in Scopus, OpenAlex, and Dimensions. Refer to “Define Data Assets” for the list of the datasets for which we evaluate coverage.\nWe subset the publication dataset from Step 2 by filtering for dataset mentions. For example, if a publication references Ag Census, it is included in the Ag Census sub-dataset; otherwise, it is excluded. This process identifies dataset-specific publication patterns in Scopus, OpenAlex, and Dimensions.\nOur approach follows a hierarchical approach to understand how USDA data assets appear in these citation databases.\n\nJournal Level – Identifies journals publishing research using USDA datasets. A journal is included if at least one of its publications references the dataset, but this does not indicate overall dataset prevalence within that journal.\nPublication Level – Examines individual publications within these journals to assess how often and in what context USDA datasets appear.\nAuthor Level – Tracks authors of these publications, analyzing institutional affiliations and research networks to understand dataset reach.\nInstitution Level – Maps dataset usage across institutions to identify geographic and organizational research patterns.\n\nThis structured approach standardizes dataset mention analysis across databases, allowing for direct comparisons of coverage and research impact.\n\n\n\nTo illustrate the data cleaning and disambiguation process, we use the Census of Agriculture as a case study to systematically compare coverage, overlap, and differences between the three citation databases. The Census of Agriculture (also referred to as “Ag Census”) is widely used in agricultural and economic research, making it an ideal dataset for assessing database differences.\n\n\n\nScopus\n\n\n\n\nTo analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON\n\n\n\n\n\n\n\n\n\nThis section presents overall statistics for Scopus and OA. Each subsection will have results reported for each dataset\nStep 4 produces two publication-level datasets: one of all academic papers released through Scopus that use Ag Census data and a similar one for OpenAlex.\nThere are 4712 unique publications reported in Scopus and 1266 in OpenAlex. These data are collapsed into a journal-level dataset based on the International Standard Serial Number (ISSN) that is unique to each academic journal."
  },
  {
    "objectID": "appendices/workflow/step03/clean_pub_data.html#sec-disambiguation",
    "href": "appendices/workflow/step03/clean_pub_data.html#sec-disambiguation",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to standardize and resolve inconsistencies in publication records by disambiguating journal names, author affiliations, and institutions across the three databases.\n\nTo compare publication coverage across citation databases, we first identify all journals that contain publications using each dataset in Scopus, OpenAlex, and Dimensions. Refer to “Define Data Assets” for the list of the datasets for which we evaluate coverage.\nWe subset the publication dataset from Step 2 by filtering for dataset mentions. For example, if a publication references Ag Census, it is included in the Ag Census sub-dataset; otherwise, it is excluded. This process identifies dataset-specific publication patterns in Scopus, OpenAlex, and Dimensions.\nOur approach follows a hierarchical approach to understand how USDA data assets appear in these citation databases.\n\nJournal Level – Identifies journals publishing research using USDA datasets. A journal is included if at least one of its publications references the dataset, but this does not indicate overall dataset prevalence within that journal.\nPublication Level – Examines individual publications within these journals to assess how often and in what context USDA datasets appear.\nAuthor Level – Tracks authors of these publications, analyzing institutional affiliations and research networks to understand dataset reach.\nInstitution Level – Maps dataset usage across institutions to identify geographic and organizational research patterns.\n\nThis structured approach standardizes dataset mention analysis across databases, allowing for direct comparisons of coverage and research impact.\n\n\n\nTo illustrate the data cleaning and disambiguation process, we use the Census of Agriculture as a case study to systematically compare coverage, overlap, and differences between the three citation databases. The Census of Agriculture (also referred to as “Ag Census”) is widely used in agricultural and economic research, making it an ideal dataset for assessing database differences.\n\n\n\nScopus\n\n\n\n\nTo analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON\n\n\n\n\n\n\n\n\n\nThis section presents overall statistics for Scopus and OA. Each subsection will have results reported for each dataset\nStep 4 produces two publication-level datasets: one of all academic papers released through Scopus that use Ag Census data and a similar one for OpenAlex.\nThere are 4712 unique publications reported in Scopus and 1266 in OpenAlex. These data are collapsed into a journal-level dataset based on the International Standard Serial Number (ISSN) that is unique to each academic journal."
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Appendix\nLinks to Sources\n\n\n\n\nData Schema\nView the primary fields and table structure.\n\n\nIPEDS Reference Files\nView the IPEDS source files and methodology.\n\n\nMSI Reference Files\nView the MSI source files and methodology.\n\n\nReplication Code\nAccess the replication code here.\n\n\nREADME File\nAccess the README file associated with replication code here.",
    "crumbs": [
      "Appendices"
    ]
  },
  {
    "objectID": "conclusions.html#expanding-dataset-usage",
    "href": "conclusions.html#expanding-dataset-usage",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Expanding Dataset Usage",
    "text": "Expanding Dataset Usage\nThis report analyzes USDA dataset usage patterns across both platforms and recommends specific strategies for expanding dataset use in underrepresented research communities.\nGiven the small percentage of MSI’s represented in our institutional analysis, it is evident that user engagement is central to increasing usage rates of the datasets, regardless of citation database."
  },
  {
    "objectID": "conclusions.html#next-steps",
    "href": "conclusions.html#next-steps",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Next Steps",
    "text": "Next Steps"
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "How to Cite:\n\n\n\nChenarides, L., Bryan, C., & Ladislau, R. (2025). Methodology for comparing citation database coverage of dataset usage. Available at: https://laurenchenarides.github.io/data_usage_report/report.html\nDownload PDF Version",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#what-is-the-issue",
    "href": "report.html#what-is-the-issue",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "What Is the Issue?",
    "text": "What Is the Issue?\nFederal datasets play an important role in supporting research across a range of disciplines. Measuring how these datasets are used can help evaluate their impact and inform future data investments. Agencies like the US Department of Agriculture (USDA) track how their datasets are referenced in research papers and disseminate data usage statistics through platforms like Democratizing Data’s Food and Agricultural Research Data Usage Dashboard and NASS’s 5 W’s Data Usage Dashboard. These tools rely on identifying dataset mentions1 in published research to develop usage statistics. Beyond reporting usage statistics, this type of analysis can also provide information about the research topics where federal datasets are applied. Understanding how federal datasets are applied helps characterize their disciplinary reach, including use in areas such as food security, nutrition, and climate, which are inherently multidisciplinary. This informs future work on identifying alternative datasets that researchers use to study similar questions across fields.\nThe process of identifying dataset mentions in academic research output has two requirements. First, citation databases provide structured access to large volumes of publication metadata, including titles, abstracts, authors, affiliations, and sometimes full-text content. Second, tracking dataset usage requires developing methods that scan publication text for dataset mentions. It is feasible to systematically identify where specific datasets are referenced across a broad set of research outputs by applying machine-learning algorithms to publication corpora collected from citation databases, allowing for scalable search and retrieval of relevant publications where datasets are mentioned. The accuracy of dataset tracking depends on the scope of research output we can access and analyze. However, different databases curate content (i.e., research output) in different ways - some focus on peer-reviewed journals while others include preprints and technical reports - and dataset tracking requires reliable citation data from citation databases.\nThis report presents a systematic review of identifying dataset mentions in research publications across various citation databases. In doing so, we compare publication, journal, and topic coverage across Scopus, OpenAlex, and Dimensions as primary sources. The purpose is to establish a consistent set of statistics for comparing results and evaluating differences in dataset tracking across citation databases. This allows for insights into how publication scope and indexing strategies influence dataset usage statistics.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#how-was-the-study-conducted",
    "href": "report.html#how-was-the-study-conducted",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "How Was the Study Conducted?",
    "text": "How Was the Study Conducted?\nThree citation databases are compared: Elsevier’s Scopus, OurResearch’s OpenAlex, and Digital Science’s Dimensions.ai.\n\nScopus charges for access to its citation database. It indexes peer-reviewed, including journal articles, conference papers, and books, and provides metadata on authorship, institutional affiliation, funding sources, and citations. For this study, Scopus was used to identify dataset mentions through a two-step process: first, Elsevier executed queries against the full-text ScienceDirect corpus and reference lists within Scopus; second, publications likely to mention USDA datasets were filtered based on keyword matching and machine learning models.\nOpenAlex, an open-source platform, offers free metadata access. It covers both traditional academic publications and other research outputs like preprints and technical reports. In this study, we used two approaches to identify dataset mentions in OpenAlex: a full-text search, which scans publication metadata fields such as titles and abstracts for references to USDA datasets,2 and a seed corpus search, which starts with a targeted set of publications based on journal, author, and topic criteria, then downloads the full text of each paper to identify mentions of USDA datasets.3\nDimensions, developed by Digital Science, is a citation database that combines free and subscription-based access. It indexes a range of research outputs, including journal articles, books, clinical trials, patents, datasets, and policy documents. Dimensions also links publications to grant and funding information. For this study, publications in Dimensions that reference USDA datasets were identified by constructing structured queries in Dimensions’ Domain Specific Language (DSL) that combined dataset aliases with institutional affiliation terms. These were executed via the dimcli API to return English-language articles from 2017–2023 with at least one U.S.-affiliated author. To maintain consistency with the criteria applied to Scopus and OpenAlex, the study focuses only on publications classified as journal articles.\n\nTo compare how these databases track dataset usage, we focus on six USDA datasets commonly used in agricultural, economic, and food policy research:\n\nAgricultural Resource Management Survey (ARMS)\nCensus of Agriculture (Ag Census)\nRural-Urban Continuum Code (RUCC)\nFood Access Research Atlas (FARA)\nFood Acquisition and Purchase Survey (FoodAPS)\nHousehold Food Security Survey Module (HHFSS)\n\nThese datasets were selected for their policy relevance, known usage frequency, and disciplinary breadth. We developed seed corpora for each dataset to identify relevant publications, then used those corpora to evaluate database coverage, topical scope, and metadata consistency.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#what-did-the-study-find",
    "href": "report.html#what-did-the-study-find",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "What Did the Study Find?",
    "text": "What Did the Study Find?\nTracking dataset mentions varies significantly depending on which citation database is used. This analysis compares Scopus, OpenAlex, and Dimensions to determine how each citation database captures research mentioning key USDA datasets. Key findings are detailed below.\n\n1. Publications\nOverlap across databases is limited. For most datasets, fewer than 10% of DOIs appear in all three sources. Scopus often identifies the largest share of indexed DOIs, especially for public health–related datasets. OpenAlex captures a broader set of publication types, including preprints and working papers. Dimensions often sits in the middle but includes the highest number of matched DOIs for some datasets.\n\n\n2. Journals\nScopus emphasizes disciplinary journals, particularly in health, economics, and social science. OpenAlex includes a mix of traditional and nontraditional outlets, including open-access platforms. Dimensions covers many of the same journals as Scopus but with a stronger presence of applied policy and public health titles.\n\n\n1.0.1 3. Topics:\nWhile the same datasets appear across all three sources, the topical classifications differ.\n\nARMS is associated with farm management, production economics, and sustainability.\nCensus of Agriculture connects to agricultural structure, environmental policy, and rural development.\nFood Access Research Atlas highlights food security, neighborhood-level inequality, and planning.\nFoodAPS centers on household behavior, SNAP, and diet cost.\nHFSSM is tied to poverty, food insecurity, and health disparities.\nRUCC connects to rural healthcare, regional planning, and demographic trends.\n\nEach source applies a different classification system, which affects how these themes are surfaced and grouped.\n\n\n4. Authors\nScopus and Dimensions tend to recover more academic authors in applied economics, public health, and nutrition. OpenAlex often identifies a wider array of author types. Across sources, many of the most active authors are affiliated with USDA Economic Research Service, major land-grant universities, and schools of public health.\n\n\n5. Institutions\nInstitutional representation varies, with Scopus and Dimensions surfacing more authors from top-tier research universities and federal agencies. OpenAlex includes more community-based organizations and international institutions not always indexed in Scopus.\n\n\nEvaluating Corpus Coverage Across Sources\nAmong the three sources examined, Dimensions offered the most consistently structured metadata linking datasets to publications. Its combination of broad journal coverage, funder metadata, and curated topic tags allowed for easier identification of research that referenced USDA datasets, particularly in applied and policy-relevant contexts.\nAlthough Scopus recovered the largest number of publications for certain datasets and fields, and OpenAlex captured a wider range of publication types (including international and open source journals), Dimensions provided the most streamlined path to assembling a usable corpus with fewer manual adjustments. This made it especially useful for mapping the reach of a dataset across disciplines and institutions.\nUltimately, each source contributed unique value to the analysis, and comparing across systems helped surface important differences in coverage and classification.\nTakeaway:\nNo single citation database captures the full scope of research publications referencing USDA datasets. Differences in indexing practices, topic labeling, and metadata structure shape what research is discoverable and how it is interpreted. Among the sources evaluated, Dimensions provided the most consistent, policy-relevant, and accessible view of dataset usage making it a strong candidate for future efforts to track the reach and impact of publicly funded data.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#how-to-use-this-report",
    "href": "report.html#how-to-use-this-report",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "How to Use This Report",
    "text": "How to Use This Report\nThis report outlines an initial approach for characterizing how USDA-related food and agriculture datasets are referenced in research publications indexed by Scopus, OpenAlex, and Dimensions. The work is not peer-reviewed but is fully transparent and reproducible, with all underlying code and procedures available for verification and reuse.\nThe report includes methods for:\n\nIdentifying publication coverage across citation databases\nCross-referencing dataset mentions across sources\nAnalyzing research topics, institutional affiliations, and author networks\n\nReusable components produced as part of this effort include:\n\nA code repository for data cleaning and standardization\nA crosswalk of data schemas by citation database\n\nThe general framework developed here can be extended to other citation systems, including Web of Science, Crossref, and Microsoft Academic, for similar evaluations of dataset coverage and usage.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#project-background",
    "href": "report.html#project-background",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.1 Project Background",
    "text": "2.1 Project Background\nTracking how federal datasets are used in academic research has been a priority for agencies such as the U.S. Department of Agriculture (USDA). Democratizing Data’s Food and Agricultural Research (FAR) Data Usage Dashboard was developed to support this effort by identifying and counting publications referencing USDA datasets. Initially built on Scopus, a proprietary citation database with structured indexing and reliable metadata, the dashboard faced limitations due to access costs and restricted journal availability.\nAs interest in open-access infrastructure has grown, OpenAlex, a free and open-source citation database developed by OurResearch, has emerged as a potential alternative. OpenAlex offers broad coverage of research outputs, including preprints and conference proceedings, and has attracted attention as a scalable replacement for proprietary systems. However, switching platforms raises questions about coverage completeness, data reliability, and how well each database supports transparent monitoring of dataset use.\nIn parallel with this evaluation, a new partnership was formed with Digital Science, the developers of Dimensions. Dimensions offers a hybrid model of free and subscription-based services and provides API access that facilitates structured identification of dataset mentions. Compared to other platforms, Dimensions includes grant metadata, standardized topic taxonomies, and curated dataset linkages, helping overcome several limitations identified in Scopus and OpenAlex.\nAlthough USDA discontinued its direct support for the dashboard, this work was taken up by the National Data Platform as part of a broader effort to build trusted infrastructure for data-driven research. To inform this transition, a systematic comparison was conducted across Scopus, OpenAlex, and Dimensions to assess their relative strengths for tracking dataset usage in food and agricultural research. The goal was not to endorse a single platform, but to provide a transparent and replicable framework for evaluating citation data quality, coverage, and relevance for public data monitoring.\n\n2.1.1 Project Objective\nThis report presents a method for tracking how six key USDA datasets (Table 1) are mentioned in research using Scopus, OpenAlex, and Dimensions. It identifies where each dataset appears, which topics they are used in, which authors and institutions are most active, and how these patterns vary depending on the citation database. The findings reveal how differences in database coverage and classification can affect assessments of dataset use.\n\n\n2.1.2 Specific Aims\nThis section outlines the core objectives guiding the database comparison and the steps used to determine how well each citation platform captures publications that mention key USDA datasets.\n\nEvaluate differences in publication coverage across citation databases. Measure the extent to which Scopus, OpenAlex, and Dimensions capture research publications that reference USDA datasets. Identify how publication inclusion varies across platforms.\nCompare journal indexing and scope. Compare the journals indexed by each database and examine how differences in journal coverage influence visibility of dataset-linked research.\nAnalyze topic coverage. Examine the research areas where USDA datasets are mentioned. Identify patterns in topic classification and assess how different citation databases support subject-level tracking of dataset usage.\nEvaluate author representation. Compare how author names are recorded across platforms, including the completeness of author metadata and potential implications for attribution and visibility.\nExamine institutional representation. Evaluate how each platform captures and standardizes institutional affiliations. Pay particular attention to differences in coverage for Minority-Serving Institutions (MSIs), land-grant universities, and other public or underrepresented institutions.\nDevelop a reproducible methodology for cross-platform comparison. Create a generalizable workflow for comparing citation databases, including steps for record linkage, deduplication, author and institution standardization, and identification of dataset mentions.\n\nThe methodology described in this report provides a systematic approach for comparing publication coverage where federal datasets are mentioned across citation databases. The scope of work includes comparing publication coverage across Scopus, OpenAlex, and Dimensions. For more information on the metadata available from each citation database, refer to this Appendix. These methods can be applied to other citation databases as alternatives to current data sources.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#data-collection",
    "href": "report.html#data-collection",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.2 Data Collection",
    "text": "2.2 Data Collection\nA core objective of this study is to evaluate publication coverage across citation databases, focusing on how well Scopus, OpenAlex, and Dimensions index research relevant to food and agricultural research. A targeted strategy was used to identify publications referencing USDA datasets, aligning with federal agency efforts to monitor and report on dataset usage. This approach enables a consistent entry point for comparison across platforms while also providing insight into the topics where federal datasets are applied and the use of complementary or alternative data sources.\nTo support this analysis, a structured inventory of USDA data assets was developed, drawing from records produced by the Economic Research Service (ERS) and the National Agricultural Statistics Service (NASS). From this broader inventory, six datasets were selected for detailed comparison based on known usage, policy relevance, and disciplinary breadth: the Census of Agriculture, Agricultural Resource Management Survey (ARMS), Food Acquisition and Purchase Survey (FoodAPS), Food Access Research Atlas (FARA), Rural-Urban Continuum Code (RUCC), and the Household Food Security Survey Module (HFSSM). The set of data assets, their producing agencies, and descriptions are presented in Table 1.\n\n\n\nTable 1: List of USDA Data Assets\n\n\n\n\n\nDataset Name\nProduced By\nDescription\n\n\n\n\nCensus of Agriculture\nNASS\nConducted every five years, it provides comprehensive data on U.S. farms, ranches, and producers.\n\n\nAgricultural Resource Management Survey (ARMS)\nERS\nA USDA survey on farm financials, production practices, and resource use.\n\n\nFood Acquisition and Purchase Survey (FoodAPS)\nERS\nA nationally representative survey tracking U.S. household food purchases and acquisitions.\n\n\nFood Access Research Atlas (FARA)\nERS\nA USDA tool mapping food access based on store locations and socioeconomic data.\n\n\nRural-Urban Continuum Code (RUCC)\nERS\nA classification system distinguishing U.S. counties by rural and urban characteristics.\n\n\nHousehold Food Security Survey Module\nERS\nA USDA survey module used to assess food insecurity levels in households.\n\n\n\n\n\n\nResearchers reference datasets in inconsistent ways—using acronyms, abbreviations, alternate spellings, or related URLs. To capture these variations, we created a structured list of dataset–alias pairs, called dyads. This Appendix provides the full list of dyads used to search for mentions of each USDA dataset across Scopus, OpenAlex, and Dimensions. This list ensures consistent and comprehensive identification of dataset mentions in research publications.\nUsing these dyads, we applied tailored search strategies across each citation database to identify relevant publications for all six datasets. These included a seed search in Scopus, a full-text metadata search in OpenAlex, a seed corpus approach in OpenAlex based on targeted filtering of journals, authors, and topics followed by full-text analysis, and a full-text search in Dimensions. Each search strategy is described in detail in the following sections.\n\n2.2.1 Scopus Approach\nThe first citation database used is Scopus, a publication catalog managed by Elsevier. Ideally, direct Scopus API access would have been used to query full publication text for mentions of USDA datasets. However, the project did not have access to the Scopus API. Only Elsevier, serving as a project partner, was able to execute queries within the Scopus environment. Consequently, the dataset mention search relied on outputs provided by Elsevier rather than independent querying.\nBecause of these constraints, a seed corpus approach was applied. First, Elsevier matched the names and aliases of all USDA datasets against full-text records available through ScienceDirect and reference sections of Scopus publications published between 2017 and 2023. This initial step identified journals, authors, and topics most likely to mention USDA datasets. A targeted search corpus was then constructed, narrowing the scope to approximately 1.45 million publications. These included various document types—articles, reviews, short surveys, notes, conference papers, chapters, books, editorials, letters, data papers, errata, and tombstones. For the purposes of this comparative report, only articles are considered.\nSeveral methods were used to identify mentions of USDA datasets in Scopus publications. First, a reference search was conducted, using exact-text matching across publication reference lists to capture formal citations of datasets. Second, full-text searches were performed using machine learning models applied to publication bodies, identifying less formal mentions of datasets. Third, machine learning routines developed through the 2021 Kaggle competition were applied to the full-text corpus to improve detection of dataset mentions, including instances where references were indirect or less structured. Details about the three machine learning models used are available here.\nBecause direct access to full publication text was not available, Elsevier shared only the extracted snippets and limited metadata. Manual validation, aided by the use of keyword flags (e.g., “USDA,” “NASS”), confirmed whether identified mentions accurately referred to the targeted datasets. To manage validation costs, only publications with at least one U.S.-based author were reviewed.\nFull documentation of the Scopus search routine, including query construction and extraction procedures, is available in this appendix..\n\n\n2.2.2 OpenAlex Approach\nThe second citation database used is OpenAlex, an open catalog of scholarly publications that provides public acess to metadata and, when available, full-text content for open-access publications via its API. Unlike Scopus, which provides controls access to licensed content, OpenAlex indexes only open-access publications or those for which open metadata has been made available by publishers.\nTwo methods were used to identify USDA dataset mentions in OpenAlex: a full-text search and a seed corpus approach. Both methods focused on peer-reviewed journal articles published between 2017 and 2023 and restricted the dataset to final published versions, excluding preprints and earlier drafts to avoid duplication across versions.\n\nMethod 1: Full-Text Search\nThis method relied on querying OpenAlex’s full-text search index using combinations of dataset aliases (e.g., alternate names, acronyms) and institutional flag terms (e.g., “USDA,” “NASS”). The combination of dataset alias and flag terms ensured that retrieved publications made an explicit connection to the correct data source. A “true” dataset mention was recorded only when at least one alias and one flag term appeared in the same publication, increasing the precision of captured dataset mentions.4\nQueries were implemented using the pyalex Python package5, which manages API requests and enforces OpenAlex’s usage rate limits. The search used the search and filter endpoints, targeting English-language, open-access articles or reviews published after 2017. Results were returned in JSON format based on the OpenAlex Work object schema, including fields for publication metadata, authorship, journal, concepts, citations, and open access status. Each record included metadata fields such as:\n\ndisplay_name (publication title)\nauthorships (authors and affiliations)\nhost_venue.display_name (journal)\ndoi (digital object identifier)\nconcepts (topics)\ncited_by_count (citation counts)\ntype (publication type, e.g., “article”)\npublication_year (year article was publish)\nlanguage (language, English only)\nis_oa (open access)\n\nFull documentation of the OpenAlex search routine, including query construction and extraction procedures, is available in this appendix..\n\nLimitations of Full-Text Search Method\nAlthough the OpenAlex API provides access to full-text search, limitations in content ingestion affect result completeness. OpenAlex receives publication text through two primary ingestion methods: PDF extraction and n-grams delivery.\nIn the PDF ingestion method, OpenAlex extracts text directly from the article PDF. However, the references section is not included in the searchable text. References are processed separately to create citation pointers between scholarly works, meaning that mentions of datasets appearing only in bibliographies are not discoverable through full-text search.\nIn the n-grams ingestion method, OpenAlex does not receive the full article text. Instead, it receives a set of extracted word sequences (n-grams) from the publisher or author. These n-grams represent fragments of text—typically short sequences of one, two, or three words—which are not guaranteed to preserve full continuous phrases. As a result, complete dataset names may be broken apart or omitted, reducing the likelihood that search queries match the intended aliases.\nThese ingestion and indexing limitations affect the completeness of results when relying solely on OpenAlex full-text search. Mentions of USDA datasets that appear either exclusively in references or are fragmented within n-grams may be missed. To address these limitations, an alternative search method was developed based on constructing a filtered seed corpus of publications for local full-text analysis.\n\n\n\nMethod 2: Seed Corpus\nTo overcome the limitations of the full-text metadata search, a seed corpus approach was developed. This method created a filtered subset of publications for local full-text analysis, targeting likely mentions of USDA datasets.\nSelection criteria for the seed corpus included:\n\nEnglish-language publications\nWorks published between 2017-2023\nPublication Type = articles\nOpen-access publications only\n\nTo focus the sample, we used results from the initial OpenAlex full-text search to identify the top 25 journals, authors, and topics most frequently associated with USDA dataset mentions. For each entity, we computed a Full-Text Search Count, which is the number of publications where USDA datasets were explicitly mentioned in the full text. This metric reflects how often each topic, journal, or author has appeared in USDA dataset–relevant research.\nWe then filtered the broader OpenAlex catalog to include all publications—regardless of whether they mentioned a dataset—linked to these top-ranked entities. This allowed us to build a more focused but expansive corpus for local text search. By narrowing to 25 entities per category, we prioritized relevance while managing scale. This process generated a structured set of JSON files containing publication metadata and links. The Python script used to flatten and process these files is provided in this appendix.\nExample: Census of Agriculture\nTo illustrate this process, consider the tables created for the Census of Agriculture dataset—Table 4 (top 25 topics), Table 5 (top 25 journals), and Table 6 (top 25 U.S.-affiliated authors). Each table contains two columns:\n\nFull-Text Search Count: Number of publications from the OpenAlex full-text search that mention the dataset and are linked to the given topic, journal, or author\nTotal Count: Total number of publications in OpenAlex associated with that topic, journal, or author, regardless of dataset mention\n\nThe Full-Text Search Count helps us identify which entities are most directly associated with USDA dataset use. For instance, if a topic like “Impact of Food Insecurity on Health Outcomes” has 78 dataset-related publications. This count reflects how often USDA datasets were mentioned within the full text of publications associated with a particular entity. Meanwhile, the OpenAlex Total Count shows the broader publication volume for that topic—in this case, over 78,000—providing context on how prominent the topic is within the full OpenAlex database. In this sense, the Full-Text Search Count serves as a rough proxy for market penetration, or how frequently a dataset appears within a given research area relative to the total volume of publications.\nThe Full-Text Search Count reflects how often USDA datasets are explicitly mentioned within a specific research area, while the Total Count represents the overall volume of publications linked to that topic, journal, or author. The large gap between these counts was a key reason for developing the seed corpus approach: even within high-relevance entities, many publications may reference datasets in ways not captured by OpenAlex’s full-text search.\nBy downloading and analyzing the full texts of all publications linked to the entities in the second column, we applied our own string-matching logic to detect mentions that OpenAlex’s indexing may have missed, particularly in reference sections or when dataset names were fragmented. This allowed us to validate and extend OpenAlex search results using a consistent and transparent local method.\nThis approach has several implications. It increases the relevance of the corpus by focusing on publications where USDA datasets are actively cited, rather than broadly associated with a topic. It also reduces processing demands by avoiding the need to download all potentially relevant PDFs. However, by prioritizing high-visibility entities from the initial search, the method may introduce selection bias and miss less frequently cited but still relevant work. The trade-off reflects a practical balance between analytical depth and operational feasibility.\nFor the Census of Agriculture, the resulting seed corpus included approximately 1.77 million unique publications. About 35% of full texts were successfully downloaded, yielding an estimated 625,000 documents for local analysis. Full-text searches on this subset improved detection of dataset mentions beyond what OpenAlex’s native indexing allowed.\nDespite the benefits, limitations remain. Full-text availability was constrained by broken or inaccessible links, and processing the corpus was computationally intensive. Future work may require distributed processing or more refined filters to improve efficiency.\nThe table below summarizes primary differences between the Full-Text Search and Seed Corpus methods. The Full-Text Search provides broader initial coverage, but it is limited by indexing constraints and lack of reference section access. The Seed Corpus narrows the search space but allows for deeper, locally controlled analysis of full-text content, including citations.\n\n\n\nTable 2: Key Differences Between OpenAlex Full-Text Search and Seed Corpus\n\n\n\n\n\n\n\n\n\n\nFeature / Criterion\nFull-Text Search\nSeed Corpus\n\n\n\n\nSearchable Sample \nOpenAlex API where has_fulltext = true\nCurated list based on known users/sources\n\n\nSource of text\nArticle body or word/phrase snippets where fulltext_origin = n-grams\nAny part of publication conditional on available PDF download\n\n\nReference sections indexed?\nNo\nYes. Will include publications that reference datasets in citations.\n\n\nFull text required? (has_fulltext)\nYes\nNot required\n\n\nOpen access required? (is_oa)\nNo\nYes. Method requires downloading the full PDF version of the article.\n\n\nSelection criteria\nNone imposed a priori\nJournal/topic/author targeting\n\n\nResulting sample\nBroad, but with limitations\nNarrower, given the target search criteria\n\n\n\n\n\n\n\n\n\n2.2.3 Dimensions\nTo identify publications mentioning USDA datasets, we used the Dimensions.ai API, following the same general methodology applied in Scopus and OpenAlex. We reused the same dataset aliases, institutional flag terms, and overall search criteria to ensure consistency across sources. The search covered scholarly publications from 2017 to 2023 and was restricted to works authored by at least one researcher affiliated with a U.S.-based institution.\nDimensions queries are written using a structured Domain Specific Language (DSL). We constructed boolean queries that combined multiple dataset aliases (e.g., “NASS Census of Agriculture”, “USDA Census”, “Agricultural Census”) with institutional identifiers (e.g., “USDA”, “NASS”, “U.S. Department of Agriculture”). As with Scopus and OpenAlex, both a dataset alias and an institutional flag term were required to appear in each result. These terms were grouped using OR within each category and then combined with an AND across categories. For example:\n\n(“NASS Census of Agriculture” OR “Census of Agriculture” OR “USDA Census of Agriculture” OR “Agricultural Census” OR “USDA Census” OR “AG Census”) AND (USDA OR “US Department of Agriculture” OR “United States Department of Agriculture” OR NASS OR “National Agricultural Statistics Service”)\n\nWe implemented this process using the dimcli Python library, which provides a streamlined interface to the Dimensions.ai API and automates result pagination. A significant advantage of this approach is the capability of the Dimensions.ai platform to manage complex searches directly, resulting in precise results and reduced computational overhead. By executing these queries directly through the API, we avoided the technical complexity associated with downloading and locally processing large amounts of textual content. Moreover, the Dimensions.ai API results can be automatically structured into an analysis-ready DataFrame format. This simplified data structure greatly facilitated our subsequent validation, data integration, and analytical workflows.\nTo maintain methodological consistency with Scopus and OpenAlex, the following filters were applied to the search:\n\nEnglish-language publications\nWorks published between 2017-2023\nDocument types: articles, chapters, proceedings, monographs, and preprints\nAuthor affiliations: Publications were filtered to include only those authored by researchers affiliated with at least one U.S.-based institution.\n\nFor comparability with the Scopus and OpenAlex samples, only publications classified as “articles” were retained for final analysis. This restriction reduces duplication across versions (e.g., preprints, proceedings) and reflects our focus on peer-reviewed scholarly output.\nFor each article, we retrieved metadata including title, authors, DOI, journal, abstract, publication date, citation counts, subject classifications, and links. These fields supported topic-level analysis, author and institution mapping, and validation of dataset mentions.\nUsing Dimensions.ai provided two main technical advantages. First, because the platform supports full-text query execution natively, we avoided the need to download or parse external files. Second, the API responses were easily converted into analysis-ready DataFrames, which simplified downstream validation and integration with other sources.\nOverall, the Dimensions.ai approach aligned with our methods for Scopus and OpenAlex, enabling consistent identification of USDA dataset mentions across all three platforms.\n\n\n2.2.4 Data Processing\nTo produce a consistent count of unique publications referencing each USDA dataset, records from three sources-Scopus, OpenAlex, and Dimensions-were consolidated, each of which identified publications through a different mechanism, described above.\nFor each source, publication-level metadata, including DOIs, journal titles, ISSNs (when available), and source-specific topic classifications was extracted. DOIs were standardized (e.g., removing URL prefixes, https://doi.org/) for consistent matching across sources. Duplicate DOIs within each source were removed. All DOIs compared in this report are associated with publications classified as document type = article and were published between 2017 and 2023.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#results",
    "href": "report.html#results",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.3 Results",
    "text": "2.3 Results\nThe aims described in Section 2.1.2 guide the development of a methodology for comparing citation databases, focusing on four areas:\n\nPublication tracking: Comparing how each platform captures publications within indexed journals\nJournal coverage: Determining which journals each platform indexes\nTopic scope: Evaluating the research areas of publications that cite USDA datasets\nAuthor and institutional affiliation: Determining how each platform records institutional information\n\nProcessed publication metadata was then merged across sources using the cleaned DOI-ISSN pairs as the common identifier. Each publication was tagged with binary indicators showing whether it appeared in Scopus, OpenAlex Full Text, OpenAlex Seed, or some combination thereof. When metadata overlapped (such as journal titles or publication years), Scopus information was prioritized, when available, given its relatively higher metadata quality, followed by OpenAlex Full Text, OpenAlex Seed, and then Dimensions.6\nThis process ensured that each publication was counted once, even if it appeared in multiple sources. The final dataset includes a deduplicated set of DOIs, along with harmonized metadata and source indicators. The number of unique publications referencing each dataset is shown in Table 3.\n\n\n\nTable 3: Unique Publications with Metadata across Sources\n\n\n\n\n\nDataset Name\nNumber of Unique Publications\n\n\n\n\nARMS\n1,581\n\n\nCensus of Agriculture\n5,835\n\n\nFood Access Research Atlas\n590\n\n\nFood Acquisition and Purchase Survey\n808\n\n\nHousehold Food Security Survey Module\n1,408\n\n\nRural-Urban Continuum Code\n2,215\n\n\n\n\n\n\nAll code used to clean, deduplicate, and merge records is provided in the GitHub repository.\n\n2.3.1 Publication Coverage\nAn objective of this report is to understand differences in publication coverage across Scopus, OpenAlex, and Dimensions. Specifically, this section asks: (1) how many and which publications referencing USDA datasets appear in each citation database, and (2) how many and which journals publishing these articles overlap between the two sources.\nIn addition, the analysis evaluates whether the different search strategies used in OpenAlex—the full-text metadata search versus the seed-corpus approach—yield substantially different sets of results.\nFor each of the six USDA datasets (Table 1) featured in this study, a treemap visualization summarizes publication coverage across the three citation databases. Each treemap groups publications into mutually exclusive categories based on their presence in one or more of the sources. The size of each box is proportional to the number of distinct DOIs in that group, providing a visual summary of relative coverage. For example, a large “Scopus only” segment indicates a high number of publications indexed exclusively in Scopus, while overlapping segments (e.g., “Scopus ∩ Dimensions”) reflect shared coverage between platforms.\n\nAgricultural Resource Management Survey (ARMS)\nOpenAlex dominates coverage for ARMS-related publications, capturing nearly 76% of all distinct DOIs exclusively. In contrast, Scopus and Dimensions contribute relatively little: just 8.9% and 5.6% of DOIs appear exclusively in those sources, respectively. Overlaps are modest, with 2.5% of DOIs shared by OpenAlex and Dimensions, and only 1.9% captured by all three. This suggests OpenAlex’s broader indexing of ARMS publications relative to the other databases.\n\n  \n\n\n\nThe Census of Agriculture\nScopus provides the broadest exclusive coverage for the Census of Agriculture, accounting for 41.3% of DOIs. Dimensions follows at 18.8%, while OpenAlex accounts for just 9.2% exclusively. The largest overlap is between Scopus and Dimensions (22.8%), with limited three-way overlap (3.6%). These results indicate that Scopus and Dimensions are the primary sources capturing publications referencing this dataset.\n\n  \n\n\n\nFood Access Research Atlas\nCoverage for this dataset is more evenly distributed. Scopus and Scopus ∩ Dimensions each account for about 24%, while OpenAlex-only coverage is 14.6%, and Dimensions-only is 11.9%. Notably, 11% of DOIs appear in all three sources. This more balanced distribution suggests broader and more consistent indexing across platforms, without a single source dominating.\n\n  \n\n\n\nThe Food Acquisition and Purchase Survey (FoodAPS)\nOpenAlex again provides the widest exclusive coverage (46.7%), while Scopus and Scopus ∩ Dimensions each contribute 17.8%. Dimensions-only coverage is modest (7.7%), and 4.7% of DOIs are shared across all three. This indicates that OpenAlex is especially important for capturing FoodAPS-related work, but combined use of all three sources increases overall visibility.\n\n  \n\n\n\nThe Household Food Security Survey Module\nScopus has the highest exclusive coverage (34.7%), followed by Scopus ∩ Dimensions (22.3%) and Dimensions-only (17.5%). OpenAlex-only coverage is lower at 12.8%, and just 5.8% of DOIs are indexed by all three. This indicates stronger coverage for HFSSM-related publications in Scopus and Dimensions compared to OpenAlex.\n\n  \n\n\n\nRural-Urban Continuum Code\nCoverage is again led by Scopus (30.8%) and Dimensions (25%), with Scopus ∩ Dimensions contributing another 24.2%. OpenAlex-only coverage is relatively low at 8.1%, and only 5.9% of DOIs are shared across all three. This pattern is consistent with datasets where OpenAlex’s coverage is more limited.\n\n  \n\n\n\n\n\n\n\nSynthesis of DOI Coverage by Source (Percent of Total DOIs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nTotal DOIs\nScopus only (%)\nOpenAlex only (%)\nDimensions only (%)\nScopus ∩ OpenAlex (%)\nScopus ∩ Dimensions (%)\nOpenAlex ∩ Dimensions (%)\nAll three (%)\n\n\n\n\nARMS\n1581\n8.9\n75.8\n5.6\n0.7\n4.6\n2.5\n1.9\n\n\nCensus of Agriculture\n5835\n41.3\n9.2\n18.8\n1.6\n22.8\n2.8\n3.6\n\n\nFood Access Research Atlas\n590\n24.4\n14.6\n11.9\n5.1\n24.7\n8.3\n11.0\n\n\nFoodAPS\n808\n17.8\n46.7\n7.7\n1.7\n17.8\n3.6\n4.7\n\n\nHFSSM\n1408\n34.7\n12.8\n17.5\n2.2\n22.3\n4.6\n5.8\n\n\nRUCC\n2215\n30.8\n8.1\n25.0\n2.3\n24.2\n3.7\n5.9\n\n\n\n\n\n\n\n\n2.3.2 Journal Coverage\nThe previous section documented substantial variation in publication coverage across Scopus, OpenAlex, and Dimensions. One potential explanation for these differences is variation in journal indexing across sources. This section examines that possibility by looking at journal coverage, specifically, whether each citation database indexes the journals where USDA dataset-related publications appear.\nFor each dataset, the analysis identifies the top 40 journals (by DOI count) and determines which citation databases index them. Sankey diagrams illustrate the relationship between citation databases (left) and journals (right). Flows indicate coverage, with journals indexed in multiple sources connected to each. While only the top 40 journals are visualized, a complete list is available in the GitHub repository.\n\nAgricultural Resource Management Survey (ARMS)\nMost top journals referencing ARMS are indexed by OpenAlex, including several high-DOI outlets such as Applied Economic Perspectives and Policy and the American Journal of Agricultural Economics. Fewer journals are exclusive to Scopus or Dimensions. This pattern aligns with OpenAlex’s dominant coverage of ARMS publications in the previous section.\n\n  \n\nClick to enlarge\n\n\n\n\nThe Census of Agriculture\nJournal coverage for Census-related publications is distributed more evenly across the three sources. Several journals—particularly in environmental and remote sensing fields—are indexed only in Scopus or Dimensions. Shared indexing is common for journals like Food Policy and Agricultural Systems, helping to explain the high level of overlap between Scopus and Dimensions.\n\n  \n\nClick to enlarge\n\n\n\n\nFood Access Research Atlas\nThis dataset is associated with journals that are broadly indexed across sources. Titles such as the Journal of Agricultural and Applied Economics and Ecological Economics are covered in all three databases. The strong overlap in journal indexing corresponds with the relatively balanced publication coverage observed in the prior section.\n\n  \n\nClick to enlarge\n\n\n\n\nThe Food Acquisition and Purchase Survey (FoodAPS)\nMany FoodAPS-related journals fall within the nutrition and behavioral sciences domains, and several of these—such as Appetite and Frontiers in Nutrition—are indexed in OpenAlex. While a subset of journals is also covered by Scopus and Dimensions, OpenAlex appears to index more of the high-volume titles, consistent with its higher share of FoodAPS-related DOIs.\n\n  \n\nClick to enlarge\n\n\n\n\nThe Household Food Security Survey Module\nThis dataset draws from a wide range of journals in public health, food policy, and applied economics. Journals such as Food Security and Journal of Nutrition Education and Behavior appear in all three sources, but some health-focused titles are only indexed in Scopus or Dimensions. These differences likely contribute to the stronger coverage seen in Scopus and Dimensions.\n\n  \n\nClick to enlarge\n\n\n\n\nRural-Urban Continuum Code\nJournals citing RUCC span health, epidemiology, and rural development. Many are indexed in Scopus and Dimensions, including Environmental Research, BMC Public Health, and Drug and Alcohol Dependence. OpenAlex has more limited coverage of these titles, consistent with its lower representation of RUCC-related DOIs.\n\n  \n\nClick to enlarge\n\n\n\n\n\n\n\n\nSummary of Journal Coverage by Dataset\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nDominant Source\nNotable Journals Indexed in All Sources\nNotable Journals Missing from Some Sources\n\n\n\n\nARMS\nOpenAlex\nAJAE, AEPP, Agribusiness\nFew missing; OpenAlex covers most top journals\n\n\nCensus of Agriculture\nScopus / Dimensions\nFood Policy, Agricultural Systems\nEnvironmental/remote sensing journals missing in OpenAlex\n\n\nFood Access Research Atlas\nShared\nJAAEA, Ecological Economics\nBroad overlap; minimal gaps\n\n\nFoodAPS\nOpenAlex\nFood Security, Frontiers in Nutrition\nSome nutrition journals missing in Scopus/Dimensions\n\n\nHFSSM\nScopus / Dimensions\nJNED, Food Security\nSome public health journals missing in OpenAlex\n\n\nRUCC\nScopus / Dimensions\nEnvironmental Research, Food Policy\nSeveral epidemiology/health titles missing in OpenAlex\n\n\n\n\n\n\n\n\n2.3.3 Publication Topics\nIn addition to differences in coverage and journal indexing, citation databases vary in how they classify research content. Each system applies a distinct taxonomy—often algorithmically generated—to assign topics to publications. These systems function like thematic filters, shaping how research is organized, discovered, and interpreted.\nTo understand how topic classification differs across sources, this section compares the most frequent topics assigned to the same set of publications by Scopus, OpenAlex, and Dimensions.\nWhy Focus on Overlapping Publications?\nTo ensure comparability, the analysis is restricted to DOIs that appear in all three databases. This approach isolates differences in classification by holding the underlying publication set constant. Any observed variation reflects how each database labels and groups the same publications.\nWord Cloud Construction\nFor each dataset, the word clouds are based on frequency tables constructed from topic metadata assigned by each source. Specifically:\n\nThe analysis filters to DOIs indexed by all three sources\nFor each source, the corresponding topic classification schema is used to generate a count of how many DOIs are linked to each topic\nThe word clouds visualize the top 100 most frequent topics assigned by each source to those shared DOIs\n\nSource-specific classification methods include:\n\nScopus: Author keywords and ASJC codes\nOpenAlex: Topic field from OpenAlex’s hierarchical ontology\nDimensions: Concepts assigned using machine learning (per Dimensions API codebook)\n\nA separate frequency table was generated for each source and dataset combination. These topic counts form the basis of the word clouds shown below.\n\nAgricultural Resource Management Survey (ARMS)\nThese word clouds illustrate the most frequent research topics associated with shared DOIs (N = 30) across Scopus, OpenAlex, and Dimensions for the Agricultural Resource Management Survey (ARMS). While all three sources reflect a core emphasis on agricultural production and economics, the specific framing and vocabulary vary by platform:\nDimensions highlights terms grounded in applied research and policy-oriented topics such as marketing channels, soil health, farm succession, and cash transfers.\nOpenAlex emphasizes conceptual and policy themes like agricultural innovations and practices, organic food and agriculture, and economic and environmental valuation.\nScopus features broader disciplinary categories and methodological terms including economics and econometrics, biofuel, development food science, and soil science.\nThe variation in topical emphasis reflects platform-specific differences in indexing practices, subject classification systems, and coverage of applied versus theoretical scholarship.\n\nScopusOpenAlexDimensions\n\n\n\n\n\n\n\n\n\n\n\n\nThe next set of word clouds summarizes the most frequent research topics associated with publications that reference a given dataset, based on each source’s topic classification schema. The first word cloud in each section aggregates topics across all sources—Scopus, OpenAlex, and Dimensions—to provide a composite view of the research landscape. Readers can then click on source-specific word clouds, which reflect the full corpus of DOIs referencing the dataset within each source. These differences highlight how each platform categorizes scholarly content and may inform decisions about dataset visibility and disciplinary reach.\n\n\n\n\n\n\nAdditional Word Cloud Variants\n\n\n\n\n\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\n\n\n\nThe Census of Agriculture\nThe word clouds below visualize the most frequent topics assigned to the 210 publications referencing the Census of Agriculture that are indexed in Scopus, OpenAlex, and Dimensions. The first image aggregates topic terms across all three sources. The remaining word clouds show how each individual source categorizes the same set of publications.\nEach classification system presents a different view of the research landscape:\nDimensions emphasizes applied agricultural practice and land management topics, such as Cover Crops, Food Systems, Land Use, and No-Till. Many of the terms reflect production methods, conservation, and on-farm activities.\nOpenAlex includes a wider range of thematic areas, with terms related to sustainability, valuation, and interdisciplinary research. Examples include Urban Agriculture and Sustainability, Economic and Environmental Valuation, and Food Waste Reduction.\nScopus reflects more traditional disciplinary structures, with emphasis on Ecology, Food Science, Economics and Econometrics, and Soil Emission. The presence of terms like China and Urban Agriculture points to geographic and policy framing as well.\nThese differences reflect variation in how each source structures and assigns topical metadata to the same publications.\n\nScopusOpenAlexDimensions\n\n\n\n\n\n\n\n\n\n\n\n\nThe next set of word clouds summarizes the most frequent research topics associated with publications that reference a given dataset, based on each source’s topic classification schema. The first word cloud in each section aggregates topics across all sources—Scopus, OpenAlex, and Dimensions—to provide a composite view of the research landscape. Readers can then click on source-specific word clouds, which reflect the full corpus of DOIs referencing the dataset within each source. These differences highlight how each platform categorizes scholarly content and may inform decisions about dataset visibility and disciplinary reach.\n\n\n\n\n\n\nAdditional Word Cloud Variants\n\n\n\n\n\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\n\n\n\nFood Access Research Atlas\nFor the 65 publications indexed across Scopus, OpenAlex, and Dimensions that reference the Food Access Research Atlas, topic classifications vary by source. Each database reflects different emphases in how it organizes subject matter related to food environments and neighborhood-level access.\nDimensions highlights terms associated with food insecurity and nutrition assistance, including Food Deserts, Food Insecurity, SNAP Participants, and Census Tracts. The topics are often grounded in program participation, geographic mapping, and diet-related outcomes, suggesting an applied framing centered on public policy and access programs.\nOpenAlex points to broader social and environmental determinants of health, with topics like Obesity, Physical Activity, Diet, Food Security and Health in Diverse Populations, and Urban Agriculture and Sustainability. Its classifications suggest greater integration of population health, urban studies, and structural considerations.\nScopus displays a mix of disciplinary and clinical topics, including Obesity, Grocery Stores, Farmers’ Markets, and Public Health. Additional terms such as Anthropology, Exercise, Surgery, and Biomedical Engineering reflect coverage from journals in the health sciences, indicating a more biomedical orientation.\nTogether, these differences suggest that Dimensions frames FARA-related research through the lens of policy and programmatic access, OpenAlex places greater emphasis on social context and urban health, and Scopus reflects disciplinary classifications from medicine, biology, and public health. These variations may influence how different audiences encounter and interpret research using this dataset.\n\nScopusOpenAlexDimensions\n\n\n\n\n\n\n\n\n\n\n\n\nThe next set of word clouds summarizes the most frequent research topics associated with publications that reference a given dataset, based on each source’s topic classification schema. The first word cloud in each section aggregates topics across all sources—Scopus, OpenAlex, and Dimensions—to provide a composite view of the research landscape. Readers can then click on source-specific word clouds, which reflect the full corpus of DOIs referencing the dataset within each source. These differences highlight how each platform categorizes scholarly content and may inform decisions about dataset visibility and disciplinary reach.\n\n\n\n\n\n\nAdditional Word Cloud Variants\n\n\n\n\n\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\n\n\n\nThe Food Acquisition and Purchase Survey (FoodAPS)\nAmong the 38 DOIs referencing FoodAPS that appear in all three citation databases, each source assigns different topic labels, offering varied perspectives on the dataset’s use in scholarly research.\nDimensions emphasizes topics directly connected to food purchasing and economic access. Prominent terms include Diet Cost, Food Environment, Thrifty Food Plan, and Supplemental Nutrition Assistance Program. These labels reflect applied work related to food affordability, policy programs, and nutrition behavior, often at the household level.\nOpenAlex highlights broader public health themes such as Obesity, Physical Activity, Diet and Food Security and Health in Diverse Populations. It also includes terms related to structural and behavioral contexts—Urban Agriculture and Sustainability, Homelessness and Social Issues, and Consumer Attitudes and Food Labeling—suggesting a focus on population-level outcomes and intersectional influences on food access.\nScopus shows more disciplinary and intervention-related topics. Terms like Grocery Stores, Farmers’ Markets, Nutrition and Dietetics, and Obesity appear frequently, alongside topics such as Brand Placement, Food Labeling, and Program Participation, indicating interest in behavioral nutrition, food marketing, and policy evaluation.\nThese differences suggest that Dimensions favors classification by programmatic and economic relevance, OpenAlex aligns more with public health and social research, and Scopus tends to organize around disciplinary domains and evaluation studies.\n\nScopusOpenAlexDimensions\n\n\n\n\n\n\n\n\n\n\n\n\nThe next set of word clouds summarizes the most frequent research topics associated with publications that reference a given dataset, based on each source’s topic classification schema. The first word cloud in each section aggregates topics across all sources—Scopus, OpenAlex, and Dimensions—to provide a composite view of the research landscape. Readers can then click on source-specific word clouds, which reflect the full corpus of DOIs referencing the dataset within each source. These differences highlight how each platform categorizes scholarly content and may inform decisions about dataset visibility and disciplinary reach.\n\n\n\n\n\n\nAdditional Word Cloud Variants\n\n\n\n\n\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\n\n\n\nThe Household Food Security Survey Module\nAmong the 82 DOIs referencing the Household Food Security Survey Module (HFSSM) that are indexed in Scopus, OpenAlex, and Dimensions, each citation database reflects a distinct emphasis in topical classification.\nDimensions highlights food insecurity, supplemental nutrition assistance, and diet quality as central themes, along with demographic and health-related topics such as older adults, physical activity, mental health, and household income. These reflect a strong policy and program-oriented lens, focused on vulnerable populations and health outcomes.\nOpenAlex surfaces broader population health and structural themes. Top topics include Food Security and Health in Diverse Populations, Obesity, Physical Activity, Diet, and Homelessness and Social Issues. The emphasis here leans toward sociomedical framing and public health determinants, especially at the community or systems level.\nScopus features terms like Food Pantries, Program Participation, and Family Characteristic, consistent with food access research. But it also brings in more disciplinary and biomedical language—Epigenetics, Cancer, Autism, and Mindfulness—pointing to research that draws on HFSSM data to explore clinical and psychological outcomes.\nTogether, these patterns show how different databases frame the same set of publications through different classification systems. While the core themes of food security and health are shared, each source emphasizes different disciplinary, policy, or structural dimensions of the research.\n\nScopusOpenAlexDimensions\n\n\n\n\n\n\n\n\n\n\n\n\nThe next set of word clouds summarizes the most frequent research topics associated with publications that reference a given dataset, based on each source’s topic classification schema. The first word cloud in each section aggregates topics across all sources—Scopus, OpenAlex, and Dimensions—to provide a composite view of the research landscape. Readers can then click on source-specific word clouds, which reflect the full corpus of DOIs referencing the dataset within each source. These differences highlight how each platform categorizes scholarly content and may inform decisions about dataset visibility and disciplinary reach.\n\n\n\n\n\n\nAdditional Word Cloud Variants\n\n\n\n\n\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\n\n\n\nRural-Urban Continuum Code\nAmong the 130 DOIs referencing the Rural-Urban Continuum Code (RUCC) dataset that appear in Scopus, OpenAlex, and Dimensions, topic classifications consistently focus on rural health disparities, healthcare access, and population-level outcomes, though each database frames these themes differently.\nDimensions places the strongest emphasis on county-level characteristics and rural infrastructure. Terms such as rural counties, older adults, cancer incidence, and opioid use disorder are prominent, reflecting the dataset’s utility for examining geographic variation in health outcomes and healthcare delivery.\nOpenAlex centers its taxonomy on population health and structural factors. Topics like opioid use disorder treatment, health disparities and outcomes, and global cancer incidence and screening signal a focus on equity and large-scale health systems research. Behavioral health and environmental health are also prominent themes.\nScopus reflects a broader mix of clinical and disciplinary topics. Frequent terms include Covid-19, cancer, public health, obesity, and health policy. Additional tags such as smoking ban, rural poverty, and Medicaid point to both policy-oriented and biomedical lines of research.\nTogether, these differences illustrate how the same publications are categorized through different topical lenses, depending on the underlying classification systems used by each database.\n\nScopusOpenAlexDimensions\n\n\n\n\n\n\n\n\n\n\n\n\nThe next set of word clouds summarizes the most frequent research topics associated with publications that reference a given dataset, based on each source’s topic classification schema. The first word cloud in each section aggregates topics across all sources—Scopus, OpenAlex, and Dimensions—to provide a composite view of the research landscape. Readers can then click on source-specific word clouds, which reflect the full corpus of DOIs referencing the dataset within each source. These differences highlight how each platform categorizes scholarly content and may inform decisions about dataset visibility and disciplinary reach.\n\n\n\n\n\n\nAdditional Word Cloud Variants\n\n\n\n\n\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\n\n\n\n\n2.3.4 Author Comparison\nTo identify and compare authors across Scopus, OpenAlex, and Dimensions, a multi-step disambiguation process was implemented. Because not all authors have persistent identifiers (e.g., ORCIDs), and because name formatting, use of initials, and institutional affiliations vary across and within sources, a harmonization pipeline was developed. This process follows the structure of the PatentsView disambiguation methodology and includes the following steps:\n\nName Normalization and Source-Specific Cleaning: Author names were extracted from each source and cleaned using a consistent normalization function. This involved transliterating special characters, removing punctuation, standardizing case, and collapsing whitespace. In each database, author records were linked to publication DOIs and enriched with affiliation information where available.\nORCID-Based Canonical Resolution: When an author’s ORCID was present—either directly in OpenAlex or indirectly via Dimensions—it was used as the canonical identifier. ORCID lookups were performed for all DOIs across sources, and a lookup table was constructed to resolve shared authors using both ORCID and cleaned name/DOI matches.\nBlocking Using Canopy Construction: For authors without ORCID identifiers, blocking keys were constructed by combining the first initial and last name to form “canopy” groups. This reduced the number of pairwise comparisons needed for clustering by limiting them to plausible matches.\nString Similarity Clustering Within Canopies: Within each canopy group, Jaro-Winkler string distances were calculated using the cleaned full names. Hierarchical clustering with average linkage was applied, and clusters were formed using a similarity threshold. Each cluster was then assigned a synthetic canonical ID based on the first observed name.\nMerging and Source Propagation: Author mentions across all three sources were merged into a master long-format table, with canonical IDs assigned based on ORCID or string-based clustering. For each publication, flags were added to indicate whether an author appeared in Scopus, OpenAlex, or Dimensions. These flags were propagated to all mentions of a given author within the same DOI.\nInstitutional Consolidation: Author affiliations were collapsed across sources by pivoting to a wide format (institution_1, institution_2, etc.) and summarizing into a primary institution field. This structure supported subsequent author-level aggregation and topic classification.\n\nThis approach enables the identification of unique authors across bibliometric systems, even in the absence of persistent identifiers. It supports comparisons of author counts, top contributors, and topic-specific participation across Scopus, OpenAlex, and Dimensions.\nMain Takeaway\nAcross all datasets, the authors most visible in one platform are not always discoverable in others. The top contributors to a dataset can vary significantly depending on which citation database is used. These differences stem from inconsistencies in metadata, name disambiguation, and indexing practices. As a result, evaluations or dashboards based on a single source may misrepresent who is using a dataset, leading to undercounting or omission of active researchers. Using multiple sources helps create a more accurate and equitable picture of scholarly engagement.\n\n\n\n\n\n\nAuthor Mentions by Dataset and Citation Database (2017–2023, Article-Type Only)\n\n\n\n\n\n\n\n\n\n\n\n\nUSDA Dataset\nUnique Authors (Scopus)\nUnique Authors (OpenAlex)\nUnique Authors (Dimensions)\n\n\n\n\nAgricultural Resource Management Survey (ARMS)\n732\n4,464\n648\n\n\nCensus of Agriculture\n13,373\n4,727\n9,320\n\n\nFood Access Research Atlas (FARA)\n1,601\n1,153\n13,588\n\n\nFood Acquisition and Purchase Survey (FoodAPS)\n1,133\n1,849\n846\n\n\nHousehold Food Security Survey Module (HFSSM)\n3,536\n1,661\n2,520\n\n\nRural-Urban Continuum Code (RUCC)\n6,894\n1,882\n6,478\n\n\n\nNote: Author counts reflect unique individuals associated with article-type publications from 2017 to 2023 that mention the specified USDA dataset in Scopus, OpenAlex, or Dimensions. Each citation database represents its own independently derived corpus, with publication inclusion determined by dataset keyword searches and metadata filters.\nThe full author-level summary by dataset and citation source is available here.\n\n\nFor purposes of this report, we feature the top 20 authors by publication count for each dataset and source. These visualizations help illustrate how platform-specific indexing affects which researchers appear most prominently. Comparing leading authors across Scopus, OpenAlex, and Dimensions reveals potential disparities in dataset visibility and discoverability.\n\nARMSCensus of AgFARAFoodAPSHFSSMRUCC\n\n\nFor ARMS, the top 20 authors identified in each platform show limited overlap. While some authors are discoverable across all three sources, others appear only in one, particularly in OpenAlex or Dimensions. This reflects inconsistencies in how author names are indexed and matched across platforms, especially for researchers who publish under multiple name variants or without ORCID identifiers.\n\n  \n\n\n\nThe Census of Agriculture shows relatively higher agreement across platforms, with many top authors appearing in multiple sources. However, there are still noticeable differences, with some authors ranked highly in one platform but not appearing at all in others. These discrepancies are likely tied to variations in how author metadata and institutional affiliations are recorded.\n\n  \n\n\n\nFARA displays substantial divergence in author coverage. A number of top authors are visible in only one platform, and overlap across all three is relatively limited. This dataset seems particularly affected by platform-specific indexing practices—likely because much of the associated research is interdisciplinary and published across a range of journal types.\n\n  \n\n\n\nFoodAPS has uneven author coverage across platforms. While some authors are picked up consistently, others are captured by only one source. OpenAlex includes several authors who are not visible in Scopus or Dimensions, suggesting that coverage differences may be especially pronounced for newer researchers or those publishing in open-access venues.\n\n  \n\n\n\nThe HFSSM dataset exhibits moderate agreement in author coverage. Most top authors are represented in at least two sources, but each platform still identifies several authors not seen in the others. This suggests that while the dataset has relatively broad exposure, gaps remain that could affect who is counted or highlighted in bibliometric analyses.\n\n  \n\n\n\nRUCC shows the widest variation in author rankings. Many authors appear in only one of the three sources, and very few are consistently represented across all. This fragmentation likely reflects the broad disciplinary scope of RUCC-related research, which spans public health, demography, and social science—fields that are not uniformly indexed across platforms.\n\n  \n\n\n\n\n\n\n2.3.5 Institutional Comparison\nIn addition to examining dataset mention coverage, the report also evaluates differences in institutional representation across Scopus, OpenAlex, and Dimensions. Each of the featured citation databases represent some portion of the global research landscape, yet their inclusion criteria and institutional coverage may vary. The purpose of this analysis is to assess which institutions are represented in each source.\n\nScopusDimensionsOpenAlex",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#conclusion",
    "href": "report.html#conclusion",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.4 Conclusion",
    "text": "2.4 Conclusion\nThis report compares how publications referencing the Census of Agriculture are captured across Scopus, OpenAlex, and Dimensions. Each platform provides only partial coverage of relevant publications, with limited overlap between sources. Variation in indexing practices, topic classification systems, and metadata availability contributes to differences in which publications, research topics, and authors are included. These discrepancies have implications for measuring the reach and influence of federal datasets and underscore the importance of carefully evaluating citation sources when assessing research use.\nThe current study aimed to include institution-level analysis using integrated IPEDS and MSI data, but full implementation was beyond the scope of the current work. An appendix provides preliminary documentation and visualization of institutional coverage patterns using harmonized IPEDS and MSI datasets from 2017 to 2023. These materials outline the steps to continue the analysis of institutional representation, particularly for Minority-Serving Institutions, but were not included in the primary results.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#footnotes",
    "href": "report.html#footnotes",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA dataset mention refers to an instance in which a specific dataset is referenced, cited, or named within a research publication. This can occur in various parts of the text, such as the abstract, methods, data section, footnotes, or references, and typically indicates that the dataset was used, analyzed, or discussed in the study.↩︎\nFull-text search in OpenAlex refers to querying the entire database for textual mentions of dataset names within titles, abstracts, and other fields.↩︎\nThe seed corpus search involves selecting a targeted set of publications based on journal, author, and topic filters. Full-text PDFs are downloaded and analyzed to identify mentions of USDA datasets not captured through metadata alone.↩︎\nThis procedure increased the likelihood of capturing genuine dataset references rather than incidental matches to individual words. Initial drafts of the query incorrectly included terms like “NASS” and “USDA” in the alias list. This was corrected to ensure that aliases strictly referred to dataset names, and flag terms referred to organizations.↩︎\nPyalex is an open-source library designed to facilitate interaction with the OpenAlex API; see https://help.openalex.org/hc/en-us/articles/27086501974551-Projects-Using-OpenAlex for more information. The package manages request formatting and automates compliance with OpenAlex’s “polite pool” rate limits, which restrict the number of requests per minute and impose backoff delays. Pyalex introduced automatic pauses between requests, with a default retry_backoff_factor of 100 milliseconds, to ensure stable and continuous retrieval. This setup enabled systematic querying while adhering to OpenAlex’s usage policies.↩︎\nIn cases where a publication appeared in more than one source, manual and programmatic checks confirmed that metadata values, such as journal titles and publication years, were consistent across sources. No conflicting values were detected.↩︎",
    "crumbs": [
      "Full Report"
    ]
  }
]